{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text To Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn Natural Language into Classes by UCF_101.\n",
    "\n",
    "First let's define some parameters of the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "rnnType     = nn.LSTM\n",
    "rnnSize     = 512\n",
    "embedSize   = 256\n",
    "itemLength  = 10\n",
    "loadEpoch   = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Vocabulary\n",
    "\n",
    "Since the model is trained on words, is necessary to have a vocabulary. This can be taken from the TextLoader Dataset class that have been created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths\n",
    "Let's define some paths in the following cell to get the dataset file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/carlo/Documents/Cognitive Computing/Text2VideoGAN/caffe/examples/s2vt/results/dataset_Action_Description.txt'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "\n",
    "current_path = !pwd\n",
    "current_path = current_path[0]\n",
    "\n",
    "dataset_path = os.path.join(current_path, 'caffe', 'examples', 's2vt', 'results', '[!val]*')\n",
    "dataset_path = glob(dataset_path)[0]\n",
    "\n",
    "dataset_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "Let's create the `TextLoader` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    TextLoader class that expects a file formatted in the following way:\n",
      "    <<(Action||Class)Name>><<tab>><<Text>>\n",
      "    E.g. Biking\tA man is riding a bicycle.\n",
      "\n",
      "    With this class you must use 0 as your Padding Character.\n",
      "\n",
      "    Constructor:\n",
      "    -----------\n",
      "        path: string\n",
      "            The path to the file that is formatted as written above.\n",
      "\n",
      "        dict_file: string\n",
      "            The path to the file that contains the dict_to_classes mapping.\n",
      "            The mapping must be as the following line:\n",
      "            E.g. 1 ApplyEyeMakeup\n",
      "\n",
      "        item_length: int\n",
      "            The requested length for each sample.\n",
      "\n",
      "    Properties:\n",
      "    ----------\n",
      "        numClasses: int\n",
      "            The len operator applied to the actions attribute of this class.\n",
      "            \n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from TextToClass.dataloading import TextLoader\n",
    "\n",
    "print(TextLoader.__doc__)\n",
    "\n",
    "dataset = TextLoader(dataset_path, item_length = itemLength)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model\n",
    "\n",
    "Finally let's create the model giving it the vocabulary wrapped from the dataset and let's load the state of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from TextToClass.models import LSTM\n",
    "\n",
    "network = LSTM(rnnType, rnnSize, embedSize, dataset.vocabulary )\n",
    "\n",
    "network.loadState(loadEpoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the Model\n",
    "\n",
    "At the end, let's see how to use the model.\n",
    "\n",
    "1. Input some text.\n",
    "2. Use the methods as shown below.\n",
    "3. Take the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put your input here: > a man is running\n",
      "Predicted class is biking\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "humanDescription     = input('Put your input here: > ')\n",
    "\n",
    "try:\n",
    "    toForwardDescription = dataset.prepareTxtForTensor(humanDescription)\n",
    "    results = network(torch.tensor(toForwardDescription).unsqueeze_(0))\n",
    "    _, actionIDx = results.max(1)\n",
    "    print(f'Predicted class is {dataset.getClassNameFromIndex(actionIDx.item())}')    \n",
    "    \n",
    "except KeyError as err:\n",
    "    print('Sorry, that word is not in the vocabulary. Please try again.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

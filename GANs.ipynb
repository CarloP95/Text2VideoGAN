{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective: generate video from text description\n",
    "\n",
    "- Download dataset UCF-101 https://www.crcv.ucf.edu/data/UCF101.php. It's an action recognition dataset, with input videos and corresponding action classes.\n",
    "\n",
    "- Download MoCoGAN code (conditional GAN model for video generation, with categorical condition): https://github.com/DLHacks/mocogan\n",
    "\n",
    "- Train MoCoGAN on UCF-101: the resulting model will be able to generate videos from action classes\n",
    "\n",
    "- Download S2VT pre-trained model (video-to-text model): https://vsubhashini.github.io/s2vt.html\n",
    "\n",
    "  - Note: S2VT uses the Caffe library. Install the library (you don't need to train the model).\n",
    "\n",
    "- Process each video in UCF-101 and get the corresponding text description. Create a dataset with input=text description and output=action class.\n",
    "\n",
    "- Train an LSTM classifier (similar to the one used in class for sentiment analysis) to classify text descriptions into actions. Report the performance.\n",
    "\n",
    "- The final model works by: getting an input text description by the user, converting it into an action class with the LSTM model, and using the action class as a condition to MoCoGAN.\n",
    "\n",
    "Note: the model will not be precise in generating video details, since conditioning is based on the class only. \n",
    "For example:\n",
    "\n",
    "\"I'm running in the park\" -> action: running\n",
    "\n",
    "\"My dog is running on the beach\" -> action: running\n",
    "\n",
    "Output videos will not actually take into account the context, but only the action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import skvideo.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/carlo/Documenti/Text2VideoGAN/mocogan/resized_data/Haircut/v_Haircut_g20_c05.mp4'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = \"/home/carlo/Documents/Cognitive Computing/Text2VideoGAN/mocogan/resized_data\"\n",
    "image_dir_name = \"*\"\n",
    "image_paths = glob(os.path.join(data_dir, image_dir_name, \"*\"))\n",
    "\n",
    "if (len(image_paths) < 1):\n",
    "    data_dir = \"/home/carlo/Documenti/Text2VideoGAN/mocogan/resized_data\"\n",
    "    image_paths = glob(os.path.join(data_dir, image_dir_name, \"*\"))\n",
    "    \n",
    "image_paths[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_video = skvideo.io.vread(image_paths[0], 96, 96)\n",
    "video =  original_video.transpose(3, 0, 1, 2) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to display a video changed by transposing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dirToSave = \"./\"\n",
    "fileName = \"transposedVideo.mp4\"\n",
    "#filepath = os.path.join(dirToSave, fileName)\n",
    "\n",
    "toSaveVideo = original_video.astype(np.uint8)\n",
    "skvideo.io.vwrite(fileName, toSaveVideo)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the necessary dependencies to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(201, 96, 96, 3) (201, 96, 96, 3)\n",
      "Imageio: 79.99903747322416, Skvideo: 79.99903747322416\n"
     ]
    }
   ],
   "source": [
    "import imageio\n",
    "import pylab\n",
    "import math\n",
    "import numpy as np\n",
    "import skvideo.io\n",
    "from glob import glob\n",
    "filenames = glob(\"/home/carlo/Documenti/Text2VideoGAN/mocogan/resized_data/*/*\")\n",
    "\n",
    "def readImageio(filename, frame= 0,show= False):\n",
    "\n",
    "    reader = imageio.get_reader(filename,  'ffmpeg')\n",
    "    \n",
    "    #nframes = math.floor(vid.get_meta_data()['fps'] * vid.get_meta_data()['duration'])\n",
    "    #shape = vid.get_meta_data()['size']\n",
    "    #n_channels = 3\n",
    "\n",
    "    #for i, im in enumerate(vid):\n",
    "        #print(i, type(im), type(np.asarray(im)), np.asarray(im).shape)\n",
    "\n",
    "    image = reader.get_data(frame)\n",
    "        \n",
    "    if show:\n",
    "        fig = pylab.figure()\n",
    "        fig.suptitle('image', fontsize=20)\n",
    "        pylab.imshow(image)\n",
    "        pylab.show()\n",
    "        \n",
    "    return np.asarray(image)\n",
    "\n",
    "def composeVideoImageio(filename):\n",
    "    \n",
    "    reader = imageio.get_reader(filename,  'ffmpeg')\n",
    "    \n",
    "    nframes = math.ceil(reader.get_meta_data()['fps'] * reader.get_meta_data()['duration'])\n",
    "    shape = reader.get_meta_data()['size']\n",
    "    \n",
    "    videodata = np.empty((nframes, shape[0], shape[1], 3))\n",
    "    \n",
    "    for idx, img in enumerate(reader):\n",
    "         videodata[idx, :, :, :] = img\n",
    "            \n",
    "    return videodata\n",
    "        \n",
    "\n",
    "res = composeVideoImageio(filenames[0])\n",
    "res_ = skvideo.io.vread(filenames[0])\n",
    "print(res_.shape, res.shape)\n",
    "\n",
    "\"\"\"for arrs in (res - res_):\n",
    "    for arr in arrs:\n",
    "        for els in arr:\n",
    "            for el in els:\n",
    "                assert el == 0.0\"\"\"\n",
    "\n",
    "skmean = res_.mean()\n",
    "imgmean = res.mean()\n",
    "\n",
    "print(f\"Imageio: {imgmean}, Skvideo: {skmean}\")\n",
    "\n",
    "assert np.isclose(skmean - imgmean, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

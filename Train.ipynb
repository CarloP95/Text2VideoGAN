{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of MoCoGAN\n",
    "---\n",
    "In this Notebook is covered the topic of training the MoCoGAN and the fine tuning of this network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining global variables and imports\n",
    "---\n",
    "In the below cell all of the imports that are needed to the training and some global variables like `device` to use the GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import skvideo.io\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim, cuda as cu, device, manual_seed\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Lambda, Compose\n",
    "\n",
    "## Try to avoid problems with dataloader.\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "try:\n",
    "    mp.set_start_method('forkserver')\n",
    "    #mp.set_start_method('spawn')\n",
    "except RuntimeError as errs:\n",
    "    print(errs)\n",
    "##########################################\n",
    "\n",
    "'''Import variables from train.py'''\n",
    "img_size = 96\n",
    "nc = 3\n",
    "ndf = 64 # from dcgan\n",
    "ngf = 64\n",
    "d_E = 10\n",
    "hidden_size = 100 # guess\n",
    "d_C = 50\n",
    "d_M = d_E\n",
    "nz  = d_C + d_M\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "T = 16 # Hyperparameter for taking #Frames into discriminator.\n",
    "\n",
    "ngpu       = 1\n",
    "batch_size = 16\n",
    "n_iter     = 120000\n",
    "pre_train  = False\n",
    "\n",
    "## Addition for training on UCF-101\n",
    "n_epochs_saveV      = 1\n",
    "n_epochs_display    = 1\n",
    "n_epochs_check      = 5\n",
    "max_frame           = 25\n",
    "cuda                = True #For compatibility with old version of MocoGan\n",
    "#### End of additions\n",
    "\n",
    "\n",
    "seed = 0\n",
    "manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = device(\"cuda\" if cu.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of Models\n",
    "From the `models` module, let's import all of the models and let's load the previous state for fine tuning.\n",
    "\n",
    "Then models are moved into the device chosen in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"./mocogan/\")\n",
    "from models import Discriminator_I, Discriminator_V, Generator_I ,GRU, UCF_101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./mocogan/models.py:207: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(params)\n",
      "./mocogan/models.py:217: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(params, 0)\n"
     ]
    }
   ],
   "source": [
    "'''Create the objects for Discriminator_(I|V), GRU and Generator_I'''\n",
    "gen_i = Generator_I(nc, ngf, nz, ngpu = 1, batch_size= batch_size)\n",
    "gru = GRU(d_E, hidden_size, gpu = cu.is_available())\n",
    "dis_i = Discriminator_I(nc, ndf, ngpu = 1)\n",
    "dis_v = Discriminator_V(nc, ndf, T = T, ngpu = 1)\n",
    "gru.initWeight()\n",
    "\n",
    "'''Move objects into the device chosen'''\n",
    "''' adjust to cuda '''\n",
    "if cuda == True:\n",
    "    dis_i.cuda()\n",
    "    dis_v.cuda()\n",
    "    gen_i.cuda()\n",
    "    gru.cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "'''Optimizer Settings and Optimizer'''\n",
    "lr = 0.0002\n",
    "betas=(0.5, 0.999)\n",
    "optim_Di  = optim.Adam(dis_i.parameters(), lr=lr, betas=betas)\n",
    "optim_Dv  = optim.Adam(dis_v.parameters(), lr=lr, betas=betas)\n",
    "optim_Gi  = optim.Adam(gen_i.parameters(), lr=lr, betas=betas)\n",
    "optim_GRU = optim.Adam(gru.parameters(),   lr=lr, betas=betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "---\n",
    "In the cells below, the dataloader will be defined and also all of the transformation that will be applied to the videos before taking them into a batch.\n",
    "To apply transformation to videos, since torchvision does not have a set of methods for this task, a repository called `torch_videovision` has been forked and modified to support transformation on numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "from torch_videovision.videotransforms.video_transforms import ColorJitter, TemporalCrop    \n",
    "from torch_videovision.videotransforms.volume_transforms import ToTensor, ClipToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = !pwd\n",
    "current_path = str(current_path[0])\n",
    "resized_path = os.path.join(current_path, \"mocogan\", 'resized_data')\n",
    "files = glob(resized_path+'/*/*')\n",
    "\n",
    "'''\n",
    "transformation = Compose([Lambda(lambda video: video.transpose(3, 0, 1, 2)/255.0),\n",
    "                            Lambda(lambda video: video[ : , : max_frame, :, : ]),\n",
    "                            Lambda(lambda video: torch.FloatTensor(video))])\n",
    "'''\n",
    "\n",
    "transformation = Compose([ ClipToTensor(numpy = True),\n",
    "                            TemporalCrop(max_frame),\n",
    "                            ToTensor()])\n",
    "\n",
    "\n",
    "dataset = UCF_101(resized_path, supportedExtensions= [\"mp4\"], transform= transformation)\n",
    "dataloader = DataLoader(dataset, batch_size= batch_size, shuffle= True, num_workers= 8, pin_memory= True, drop_last= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "---\n",
    "\n",
    "In the cells below, first some methods to generate the Noise needed for the GAN is defined, then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Utilities'''\n",
    "def trim(video):\n",
    "    start = np.random.randint(0, video.shape[1] - (T+1))\n",
    "    end = start + T\n",
    "    return video[:, start:end, :, :]\n",
    "\n",
    "# for input noises to generate fake video\n",
    "# note that noises are trimmed randomly from n_frames to T for efficiency\n",
    "def trim_noise(noise):\n",
    "    #print(\"-----TRIMMING NOISE-----\")\n",
    "    #print(f\"Noise Size: {noise.size()}\")\n",
    "    start = np.random.randint(0, noise.size(1) - (T+1))\n",
    "    end = start + T\n",
    "    #print(\"-----END OF TRIMMING NOISE-----\")\n",
    "    return noise[:, start:end, :, :, :]\n",
    "\n",
    "\n",
    "''' calc grad of models '''\n",
    "\n",
    "def bp_i(inputs, y, retain=False):\n",
    "    label = (torch.FloatTensor()).cuda()\n",
    "    label.resize_(inputs.size(0)).fill_(y)\n",
    "    labelv = Variable(label)\n",
    "    outputs = dis_i(inputs)\n",
    "    err = criterion(outputs, labelv)\n",
    "    err.backward(retain_graph=retain)\n",
    "    toReturnErr = err.data[0] if err.size() == torch.Tensor().size() else err.item()\n",
    "    return toReturnErr, outputs.data.mean()\n",
    "\n",
    "def bp_v(inputs, labels, y, retain=False):\n",
    "    #print(\"----BackPropagate_V-----\")\n",
    "    #print(inputs.size())\n",
    "    label = (torch.FloatTensor()).cuda()\n",
    "    try:\n",
    "        label.resize_(inputs.size(0)).fill_(y)\n",
    "\n",
    "    except RuntimeError as _:\n",
    "        # Dimension of y does not allow to use fill_\n",
    "        assert(inputs.size(0) == y.size(0))\n",
    "        label = (torch.FloatTensor(y)).cuda()\n",
    "\n",
    "    labelv = Variable(label)\n",
    "    outputs = dis_v(inputs, labels)\n",
    "    err = criterion(outputs, labelv)\n",
    "    err.backward(retain_graph=retain)\n",
    "    toReturnErr = err.data[0] if err.size() == torch.Tensor().size() else err.item()\n",
    "    #print(\"----End of BackPropagate_V-----\")\n",
    "    return toReturnErr, outputs.data.mean()\n",
    "\n",
    "\n",
    "''' gen input noise for fake video '''\n",
    "\n",
    "def gen_z(n_frames, batch_size = batch_size):\n",
    "    #print(\"----Generating Z-----\")\n",
    "    #print(f\"N_FRAMES: {n_frames}\")\n",
    "    #print(f\"BATCH_SIZE: {batch_size}\")\n",
    "    #print(f\"D_C: {d_C}\")\n",
    "    #print(f\"D_E: {d_E}\")\n",
    "    #print(f\"nz: {nz}\")\n",
    "    z_C = Variable(torch.randn(batch_size, d_C))\n",
    "    #  repeat z_C to (batch_size, n_frames, d_C)\n",
    "    z_C = z_C.unsqueeze(1).repeat(1, n_frames, 1)\n",
    "    eps = Variable(torch.randn(batch_size, d_E))\n",
    "    if cuda == True:\n",
    "        z_C, eps = z_C.cuda(), eps.cuda()\n",
    "\n",
    "    gru.initHidden(batch_size)\n",
    "    # notice that 1st dim of gru outputs is seq_len, 2nd is batch_size\n",
    "    z_M = gru(eps, n_frames).transpose(1, 0)\n",
    "    z = torch.cat((z_M, z_C), 2)  # z.size() => (batch_size, n_frames, nz)\n",
    "    #print(\"----End Generating Z-----\")\n",
    "    return z.view(batch_size, n_frames, nz, 1, 1)\n",
    "\n",
    "''' prepare for train '''\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    d = math.floor(s / ((60**2)*24))\n",
    "    h = math.floor(s / (60**2)) - d*24\n",
    "    m = math.floor(s / 60) - h*60 - d*24*60\n",
    "    s = s - m*60 - h*(60**2) - d*24*(60**2)\n",
    "    return '%dd %dh %dm %ds' % (d, h, m, s)\n",
    "\n",
    "trained_path = os.path.join(current_path, \"mocogan\", 'trained_models')\n",
    "def checkpoint(model, optimizer, epoch):\n",
    "    filename = os.path.join(trained_path, '%s_epoch-%d' % (model.__class__.__name__, epoch))\n",
    "    torch.save(model.state_dict(), filename + '.model')\n",
    "    torch.save(optimizer.state_dict(), filename + '.state')\n",
    "\n",
    "def save_video(fake_video, epoch):\n",
    "    outputdata = fake_video * 255\n",
    "    outputdata = outputdata.astype(np.uint8)\n",
    "    dir_path = os.path.join(current_path, 'mocogan', 'generated_videos')\n",
    "    file_path = os.path.join(dir_path, 'fakeVideo_epoch-%d.mp4' % (epoch))\n",
    "    skvideo.io.vwrite(file_path, outputdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' train models '''\n",
    "def train():\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Starting training: CUDA is { 'On' if cuda == True else 'Off'}\")\n",
    "\n",
    "    for epoch in range(1, n_iter+1):\n",
    "        ''' prepare real images '''\n",
    "        # real_videos.size() => (batch_size, nc, T, img_size, img_size)\n",
    "\n",
    "        # Get data iterator\n",
    "        fake_label = 0\n",
    "        true_label = [val for val in range(1, 102)]\n",
    "        data_iter = iter(dataloader) #Iterator\n",
    "        data_len = len(dataloader) #Num Batches\n",
    "        data_i = 0\n",
    "\n",
    "        while data_i < data_len:\n",
    "\n",
    "            try:\n",
    "          \n",
    "                (real_videos, labels) = next(data_iter)\n",
    "                  \n",
    "                print(f\"--------Batch {data_i}/{data_len}---------\\r\")\n",
    "                #for (key, val) in dataset.class_to_idx.items():\n",
    "                #    if ( val in labels.tolist() ):\n",
    "                #        #print(key)\n",
    "                #        pass\n",
    "\n",
    "                if cuda == True:\n",
    "                    real_videos = real_videos.cuda()\n",
    "                    labels = labels.cuda()\n",
    "\n",
    "                real_videos = Variable(real_videos)\n",
    "                real_img = real_videos[:, :, np.random.randint(0, T), :, :]\n",
    "\n",
    "                ''' prepare fake images '''\n",
    "                # note that n_frames is sampled from video length distribution\n",
    "                if (len(dataset.videoLengths) > 0):\n",
    "                    randomVideo = list(dataset.videoLengths)[np.random.randint(0, len(dataset.videoLengths))]\n",
    "                    n_frames = dataset.videoLengths[randomVideo]\n",
    "          \n",
    "                else: # Use this for first iterations, when dataset.videoLengths is not yet updated.\n",
    "                    n_frames = T + 2 + np.random.randint(0, real_videos.size()[2])\n",
    "          \n",
    "                Z = gen_z(n_frames, batch_size)  # Z.size() => (batch_size, n_frames, nz, 1, 1)\n",
    "                # trim => (batch_size, T, nz, 1, 1)\n",
    "                Z = trim_noise(Z)\n",
    "                # generate videos\n",
    "                Z = Z.contiguous().view(batch_size*T, nz, 1, 1)\n",
    "                \n",
    "                fake_videos = gen_i(Z, labels)\n",
    "                fake_videos = fake_videos.view(batch_size, T, nc, img_size, img_size)\n",
    "                # transpose => (batch_size, nc, T, img_size, img_size)\n",
    "                fake_videos = fake_videos.transpose(2, 1)\n",
    "                # img sampling\n",
    "                fake_img = fake_videos[:, :, np.random.randint(0, T), :, :]\n",
    "\n",
    "                ''' train discriminators '''\n",
    "                # video\n",
    "                dis_v.zero_grad()\n",
    "                randomStartFrameIdx = np.random.randint(0, real_videos.size()[2] - T - 1)\n",
    "                #print(\"-----INFOS-----\")\n",
    "                #print(f\"RandomStartFrame:{randomStartFrameIdx}\")\n",
    "                #print(f\"Video Size:{real_videos.size()}\")\n",
    "                #print(\"-----END OF INFOS-----\")\n",
    "                croppedRealVideos = real_videos[:,:,randomStartFrameIdx: randomStartFrameIdx + T, :, :]\n",
    "                err_Dv_real, Dv_real_mean = bp_v(croppedRealVideos, labels, 0.9)\n",
    "                #err_Dv_real, Dv_real_mean = bp_v(croppedRealVideos, labels.type(torch.FloatTensor) / len(dictClassesIdx))\n",
    "                err_Dv_fake, Dv_fake_mean = bp_v(fake_videos.detach(), labels, fake_label)\n",
    "                err_Dv = err_Dv_real + err_Dv_fake\n",
    "                optim_Dv.step()\n",
    "                # image\n",
    "                dis_i.zero_grad()\n",
    "                err_Di_real, Di_real_mean = bp_i(real_img, 0.9)\n",
    "                err_Di_fake, Di_fake_mean = bp_i(fake_img.detach(), fake_label)\n",
    "                err_Di = err_Di_real + err_Di_fake\n",
    "                optim_Di.step()\n",
    "\n",
    "\n",
    "                ''' train generators '''\n",
    "                gen_i.zero_grad()\n",
    "                gru.zero_grad()\n",
    "                # video. notice retain=True for back prop twice\n",
    "                err_Gv, _ = bp_v(fake_videos, labels, 0.9, retain=True)\n",
    "                # images\n",
    "                err_Gi, _ = bp_i(fake_img, 0.9)\n",
    "                optim_Gi.step()\n",
    "                optim_GRU.step()\n",
    "\n",
    "                '''Increment index for Batch'''\n",
    "                data_i = data_i + 1\n",
    "          \n",
    "                '''Cool down the Hardware'''\n",
    "                time.sleep(1)\n",
    "          \n",
    "            except StopIteration:\n",
    "                break\n",
    "            \n",
    "            except KeyboardInterrupt:\n",
    "                save_video(fake_videos[0].data.cpu().numpy().transpose(1, 2, 3, 0), epoch)\n",
    "                checkpoint(dis_i, optim_Di, epoch)\n",
    "                checkpoint(dis_v, optim_Dv, epoch)\n",
    "                checkpoint(gen_i, optim_Gi, epoch)\n",
    "                checkpoint(gru,   optim_GRU, epoch)\n",
    "\n",
    "        if epoch % n_epochs_display == 0:\n",
    "            print('[%d/%d] (%s) Loss_Di: %.4f Loss_Dv: %.4f Loss_Gi: %.4f Loss_Gv: %.4f Di_real_mean %.4f Di_fake_mean %.4f Dv_real_mean %.4f Dv_fake_mean %.4f'\n",
    "                  % (epoch, n_iter, timeSince(start_time), err_Di, err_Dv, err_Gi, err_Gv, Di_real_mean, Di_fake_mean, Dv_real_mean, Dv_fake_mean))\n",
    "\n",
    "        if epoch % n_epochs_saveV == 0:\n",
    "            save_video(fake_videos[0].data.cpu().numpy().transpose(1, 2, 3, 0), epoch)\n",
    "\n",
    "        if epoch % n_epochs_check == 0:\n",
    "            checkpoint(dis_i, optim_Di, epoch)\n",
    "            checkpoint(dis_v, optim_Dv, epoch)\n",
    "            checkpoint(gen_i, optim_Gi, epoch)\n",
    "            checkpoint(gru,   optim_GRU, epoch)\n",
    "          \n",
    "        '''Cool down the Hardware'''\n",
    "        time.sleep(10)\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Previous State\n",
    "---\n",
    "If wanted, the following cell can be used to load the previous state of a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' use pre-trained models '''\n",
    "\n",
    "def load():\n",
    "    dis_i.load_state_dict(torch.load(trained_path + '/Discriminator_I.model'))\n",
    "    dis_v.load_state_dict(torch.load(trained_path + '/Discriminator_V.model'))\n",
    "    gen_i.load_state_dict(torch.load(trained_path + '/Generator_I.model'))\n",
    "    gru.load_state_dict(torch.load(trained_path + '/GRU.model'))\n",
    "    optim_Di.load_state_dict(torch.load(trained_path + '/Discriminator_I.state'))\n",
    "    optim_Dv.load_state_dict(torch.load(trained_path + '/Discriminator_V.state'))\n",
    "    optim_Gi.load_state_dict(torch.load(trained_path + '/Generator_I.state'))\n",
    "    optim_GRU.load_state_dict(torch.load(trained_path + '/GRU.state'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, start training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training: CUDA is On\n",
      "--------Batch 0/832---------\n",
      "--------Batch 1/832---------\n",
      "--------Batch 2/832---------\n",
      "--------Batch 3/832---------\n",
      "--------Batch 4/832---------\n",
      "--------Batch 5/832---------\n",
      "--------Batch 6/832---------\n",
      "--------Batch 7/832---------\n",
      "--------Batch 8/832---------\n",
      "--------Batch 9/832---------\n",
      "--------Batch 10/832---------\n",
      "--------Batch 11/832---------\n",
      "--------Batch 12/832---------\n",
      "--------Batch 13/832---------\n",
      "--------Batch 14/832---------\n",
      "--------Batch 15/832---------\n",
      "--------Batch 16/832---------\n",
      "--------Batch 17/832---------\n",
      "--------Batch 18/832---------\n",
      "--------Batch 19/832---------\n",
      "--------Batch 20/832---------\n",
      "--------Batch 21/832---------\n",
      "--------Batch 22/832---------\n",
      "--------Batch 23/832---------\n",
      "--------Batch 24/832---------\n",
      "--------Batch 25/832---------\n",
      "--------Batch 26/832---------\n",
      "--------Batch 27/832---------\n",
      "--------Batch 28/832---------\n",
      "--------Batch 29/832---------\n",
      "--------Batch 30/832---------\n",
      "--------Batch 31/832---------\n",
      "--------Batch 32/832---------\n",
      "--------Batch 33/832---------\n",
      "--------Batch 34/832---------\n",
      "--------Batch 35/832---------\n",
      "--------Batch 36/832---------\n",
      "--------Batch 37/832---------\n",
      "--------Batch 38/832---------\n",
      "--------Batch 39/832---------\n",
      "--------Batch 40/832---------\n",
      "--------Batch 41/832---------\n",
      "--------Batch 42/832---------\n",
      "--------Batch 43/832---------\n",
      "--------Batch 44/832---------\n",
      "--------Batch 45/832---------\n",
      "--------Batch 46/832---------\n",
      "--------Batch 47/832---------\n",
      "--------Batch 48/832---------\n",
      "--------Batch 49/832---------\n",
      "--------Batch 50/832---------\n",
      "--------Batch 51/832---------\n",
      "--------Batch 52/832---------\n",
      "--------Batch 53/832---------\n",
      "--------Batch 54/832---------\n",
      "--------Batch 55/832---------\n",
      "--------Batch 56/832---------\n",
      "--------Batch 57/832---------\n",
      "--------Batch 58/832---------\n",
      "--------Batch 59/832---------\n",
      "--------Batch 60/832---------\n",
      "--------Batch 61/832---------\n",
      "--------Batch 62/832---------\n",
      "--------Batch 63/832---------\n",
      "--------Batch 64/832---------\n",
      "--------Batch 65/832---------\n",
      "--------Batch 66/832---------\n",
      "--------Batch 67/832---------\n",
      "--------Batch 68/832---------\n",
      "--------Batch 69/832---------\n",
      "--------Batch 70/832---------\n",
      "--------Batch 71/832---------\n",
      "--------Batch 72/832---------\n",
      "--------Batch 73/832---------\n",
      "--------Batch 74/832---------\n",
      "--------Batch 75/832---------\n",
      "--------Batch 76/832---------\n",
      "--------Batch 77/832---------\n",
      "--------Batch 78/832---------\n",
      "--------Batch 79/832---------\n",
      "--------Batch 80/832---------\n",
      "--------Batch 81/832---------\n",
      "--------Batch 82/832---------\n",
      "--------Batch 83/832---------\n",
      "--------Batch 84/832---------\n",
      "--------Batch 85/832---------\n",
      "--------Batch 86/832---------\n",
      "--------Batch 87/832---------\n",
      "--------Batch 88/832---------\n",
      "--------Batch 89/832---------\n",
      "--------Batch 90/832---------\n",
      "--------Batch 91/832---------\n",
      "--------Batch 92/832---------\n",
      "--------Batch 93/832---------\n",
      "--------Batch 94/832---------\n",
      "--------Batch 95/832---------\n",
      "--------Batch 96/832---------\n",
      "--------Batch 97/832---------\n",
      "--------Batch 98/832---------\n",
      "--------Batch 99/832---------\n",
      "--------Batch 100/832---------\n",
      "--------Batch 101/832---------\n",
      "--------Batch 102/832---------\n",
      "--------Batch 103/832---------\n",
      "--------Batch 104/832---------\n",
      "--------Batch 105/832---------\n",
      "--------Batch 106/832---------\n",
      "--------Batch 107/832---------\n",
      "--------Batch 108/832---------\n",
      "--------Batch 109/832---------\n",
      "--------Batch 110/832---------\n",
      "--------Batch 111/832---------\n",
      "--------Batch 112/832---------\n",
      "--------Batch 113/832---------\n",
      "--------Batch 114/832---------\n",
      "--------Batch 115/832---------\n",
      "--------Batch 116/832---------\n",
      "--------Batch 117/832---------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 16398, 16405, 16410, 16415, 16420, 16432, 16437) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    510\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    512\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    171\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a9693ee7e205>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-42101df6e594>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mreal_videos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"--------Batch {data_i}/{data_len}---------\\r\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    574\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 576\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_batch\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 519\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    520\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 16398, 16405, 16410, 16415, 16420, 16432, 16437) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "#load()\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

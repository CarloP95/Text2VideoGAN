{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of MoCoGAN\n",
    "---\n",
    "In this Notebook is covered the topic of training the MoCoGAN and the fine tuning of this network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining global variables and imports\n",
    "---\n",
    "In the below cell all of the imports that are needed to the training and some global variables like `device` to use the GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import skvideo.io\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim, cuda as cu, device, manual_seed\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torchvision.transforms import Lambda, Compose\n",
    "\n",
    "'''Import variables from train.py'''\n",
    "img_size = 96\n",
    "nc = 3\n",
    "ndf = 64 # from dcgan\n",
    "ngf = 64\n",
    "d_E = 10\n",
    "hidden_size = 100 # guess\n",
    "d_C = 50\n",
    "d_M = d_E\n",
    "nz  = d_C + d_M\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "T = 16 # Hyperparameter for taking #Frames into discriminator.\n",
    "\n",
    "ngpu       = 1\n",
    "batch_size = 16\n",
    "n_iter     = 120000\n",
    "pre_train  = False\n",
    "\n",
    "## Addition for training on UCF-101\n",
    "n_epochs_saveV      = 10\n",
    "n_epochs_display    = 1\n",
    "n_epochs_check      = 10\n",
    "max_frame           = 25\n",
    "cuda                = True #For compatibility with old version of MocoGan\n",
    "#### End of additions\n",
    "\n",
    "\n",
    "seed = 0\n",
    "manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = device(\"cuda\" if cu.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of Models\n",
    "From the `models` module, let's import all of the models and let's load the previous state for fine tuning.\n",
    "\n",
    "Then models are moved into the device chosen in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"./mocogan/\")\n",
    "from models import Discriminator_I, Discriminator_V, Generator_I ,GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./mocogan/models.py:155: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(params)\n",
      "./mocogan/models.py:165: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(params, 0)\n"
     ]
    }
   ],
   "source": [
    "'''Create the objects for Discriminator_(I|V), GRU and Generator_I'''\n",
    "gen_i = Generator_I(nc, ngf, nz, ngpu = 1)\n",
    "gru = GRU(d_E, hidden_size, gpu = cu.is_available())\n",
    "dis_i = Discriminator_I(nc, ndf, ngpu = 1)\n",
    "dis_v = Discriminator_V(nc, ndf, T = T, ngpu = 1)\n",
    "gru.initWeight()\n",
    "\n",
    "'''Move objects into the device chosen'''\n",
    "''' adjust to cuda '''\n",
    "if cuda == True:\n",
    "    dis_i.cuda()\n",
    "    dis_v.cuda()\n",
    "    gen_i.cuda()\n",
    "    gru.cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "'''Optimizer Settings and Optimizer'''\n",
    "lr = 0.0002\n",
    "betas=(0.5, 0.999)\n",
    "optim_Di  = optim.Adam(dis_i.parameters(), lr=lr, betas=betas)\n",
    "optim_Dv  = optim.Adam(dis_v.parameters(), lr=lr, betas=betas)\n",
    "optim_Gi  = optim.Adam(gen_i.parameters(), lr=lr, betas=betas)\n",
    "optim_GRU = optim.Adam(gru.parameters(),   lr=lr, betas=betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "---\n",
    "In the cells below, the dataloader will be defined and also all of the transformation that will be applied to the videos before taking them into a batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = !pwd\n",
    "current_path = str(current_path[0])\n",
    "resized_path = os.path.join(current_path, \"mocogan\", 'resized_data')\n",
    "files = glob(resized_path+'/*/*')\n",
    "\n",
    "#transformation = Compose([ToTensor(), Lambda(lambda tensor: (tensor - tensor.mean() )/ tensor.std())])\n",
    "\n",
    "transformation = Compose([Lambda(lambda video: video.transpose(3, 0, 1, 2)/255.0),\n",
    "                            Lambda(lambda video: video[ : , : max_frame, :, : ]),\n",
    "                            Lambda(lambda video: torch.FloatTensor(video))])\n",
    "\n",
    "filenameDictClassesIdx = \"classInd.txt\"\n",
    "dictClassesIdx = {}\n",
    "try:\n",
    "    with open(os.path.join(current_path, \"ucfTrainTestlist\", filenameDictClassesIdx)) as file:\n",
    "        for line in file:\n",
    "            dictClassesIdx[ line.split() [1]] = int( line.split() [0] )\n",
    "            \n",
    "except FileNotFoundError as _:\n",
    "    with open(os.path.join(current_path, \"mocogan\", \"ucfTrainTestlist\", filenameDictClassesIdx)) as file:\n",
    "        for line in file:\n",
    "            dictClassesIdx[ line.split() [1]] = int( line.split() [0] )\n",
    "\n",
    "# dataset = DatasetFolder(resized_path, loadVideo, [\"mp4\"], transform= transformation)\n",
    "dataset = DatasetFolder(resized_path, skvideo.io.vread, [\"mp4\"], transform= transformation)\n",
    "dataset.class_to_idx = dictClassesIdx\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size= batch_size, shuffle= True, num_workers= 8, pin_memory= True, drop_last= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General configuration for OpenCV 3.1.0 =====================================\n",
      "  Version control:               unknown\n",
      "\n",
      "  Platform:\n",
      "    Host:                        Linux 4.8.12-040812-generic x86_64\n",
      "    CMake:                       3.6.3\n",
      "    CMake generator:             Unix Makefiles\n",
      "    CMake build tool:            /usr/bin/make\n",
      "    Configuration:               Release\n",
      "\n",
      "  C/C++:\n",
      "    Built as dynamic libs?:      YES\n",
      "    C++ Compiler:                /usr/bin/c++  (ver 4.6.3)\n",
      "    C++ flags (Release):         -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -msse -msse2 -mno-avx -msse3 -mno-ssse3 -mno-sse4.1 -mno-sse4.2 -ffunction-sections -fvisibility=hidden -fvisibility-inlines-hidden -fopenmp -O3 -DNDEBUG  -DNDEBUG\n",
      "    C++ flags (Debug):           -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -msse -msse2 -mno-avx -msse3 -mno-ssse3 -mno-sse4.1 -mno-sse4.2 -ffunction-sections -fvisibility=hidden -fvisibility-inlines-hidden -fopenmp -g  -O0 -DDEBUG -D_DEBUG\n",
      "    C Compiler:                  /usr/bin/cc\n",
      "    C flags (Release):           -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -msse -msse2 -mno-avx -msse3 -mno-ssse3 -mno-sse4.1 -mno-sse4.2 -ffunction-sections -fvisibility=hidden -fopenmp -O3 -DNDEBUG  -DNDEBUG\n",
      "    C flags (Debug):             -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -msse -msse2 -mno-avx -msse3 -mno-ssse3 -mno-sse4.1 -mno-sse4.2 -ffunction-sections -fvisibility=hidden -fopenmp -g  -O0 -DDEBUG -D_DEBUG\n",
      "    Linker flags (Release):\n",
      "    Linker flags (Debug):\n",
      "    Precompiled headers:         YES\n",
      "    Extra dependencies:          gtk-x11-2.0 gdk-x11-2.0 atk-1.0 gio-2.0 pangoft2-1.0 pangocairo-1.0 gdk_pixbuf-2.0 cairo pango-1.0 freetype fontconfig gobject-2.0 gthread-2.0 glib-2.0 dl m pthread rt\n",
      "    3rdparty dependencies:       zlib libjpeg libwebp libpng libtiff libjasper IlmImf libprotobuf\n",
      "\n",
      "  OpenCV modules:\n",
      "    To be built:                 core flann imgproc ml photo reg surface_matching video dnn fuzzy imgcodecs shape videoio highgui objdetect plot superres xobjdetect xphoto bgsegm bioinspired dpm face features2d line_descriptor saliency text calib3d ccalib datasets java rgbd stereo structured_light tracking videostab xfeatures2d ximgproc aruco optflow stitching python3\n",
      "    Disabled:                    world contrib_world\n",
      "    Disabled by dependency:      -\n",
      "    Unavailable:                 cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev python2 ts viz cvv hdf matlab sfm\n",
      "\n",
      "  GUI: \n",
      "    QT:                          NO\n",
      "    GTK+ 2.x:                    YES (ver 2.24.10)\n",
      "    GThread :                    YES (ver 2.32.4)\n",
      "    GtkGlExt:                    NO\n",
      "    OpenGL support:              NO\n",
      "    VTK support:                 NO\n",
      "\n",
      "  Media I/O: \n",
      "    ZLib:                        build (ver 1.2.8)\n",
      "    JPEG:                        build (ver 90)\n",
      "    WEBP:                        build (ver 0.3.1)\n",
      "    PNG:                         build (ver 1.6.19)\n",
      "    TIFF:                        build (ver 42 - 4.0.2)\n",
      "    JPEG 2000:                   build (ver 1.900.1)\n",
      "    OpenEXR:                     build (ver 1.7.1)\n",
      "    GDAL:                        NO\n",
      "\n",
      "  Video I/O:\n",
      "    DC1394 1.x:                  NO\n",
      "    DC1394 2.x:                  NO\n",
      "    FFMPEG:                      NO\n",
      "      codec:                     NO\n",
      "      format:                    NO\n",
      "      util:                      NO\n",
      "      swscale:                   NO\n",
      "      resample:                  NO\n",
      "      gentoo-style:              NO\n",
      "    GStreamer:                   NO\n",
      "    OpenNI:                      NO\n",
      "    OpenNI PrimeSensor Modules:  NO\n",
      "    OpenNI2:                     NO\n",
      "    PvAPI:                       NO\n",
      "    GigEVisionSDK:               NO\n",
      "    UniCap:                      NO\n",
      "    UniCap ucil:                 NO\n",
      "    V4L/V4L2:                    NO/YES\n",
      "    XIMEA:                       NO\n",
      "    Xine:                        NO\n",
      "    gPhoto2:                     NO\n",
      "\n",
      "  Parallel framework:            OpenMP\n",
      "\n",
      "  Other third-party libraries:\n",
      "    Use IPP:                     9.0.1 [9.0.1]\n",
      "         at:                     /home/travis/miniconda/conda-bld/conda_1486587069159/work/opencv-3.1.0/3rdparty/ippicv/unpack/ippicv_lnx\n",
      "    Use IPP Async:               NO\n",
      "    Use VA:                      NO\n",
      "    Use Intel VA-API/OpenCL:     NO\n",
      "    Use Eigen:                   YES (ver 3.2.7)\n",
      "    Use Cuda:                    NO\n",
      "    Use OpenCL:                  NO\n",
      "    Use custom HAL:              NO\n",
      "\n",
      "  Python 2:\n",
      "    Interpreter:                 /usr/bin/python2.7 (ver 2.7.3)\n",
      "\n",
      "  Python 3:\n",
      "    Interpreter:                 /home/carlo/anaconda3/bin/python (ver 3.6)\n",
      "    Libraries:                   /home/carlo/anaconda3/lib/libpython3.6m.so (ver 3.6.0)\n",
      "    numpy:                       /home/carlo/anaconda3/lib/python3.6/site-packages/numpy/core/include (ver 1.11.3)\n",
      "    packages path:               lib/python3.6/site-packages\n",
      "\n",
      "  Python (for build):            /usr/bin/python2.7\n",
      "\n",
      "  Java:\n",
      "    ant:                         /usr/bin/ant (ver 1.8.2)\n",
      "    JNI:                         /usr/lib/jvm/java-7-openjdk-amd64/include /usr/lib/jvm/java-7-openjdk-amd64/include /usr/lib/jvm/java-7-openjdk-amd64/include\n",
      "    Java wrappers:               YES\n",
      "    Java tests:                  NO\n",
      "\n",
      "  Matlab:                        Matlab not found or implicitly disabled\n",
      "\n",
      "  Tests and samples:\n",
      "    Tests:                       NO\n",
      "    Performance tests:           NO\n",
      "    C/C++ Examples:              NO\n",
      "\n",
      "  Install path:                  /home/carlo/anaconda3\n",
      "\n",
      "  cvconfig.h is in:              /home/travis/miniconda/conda-bld/conda_1486587069159/work/opencv-3.1.0/build\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "print( cv2.getBuildInformation() )\n",
    "\n",
    "def loadVideo(videoName):    \n",
    "    print(f\"[CV2] Loading : {videoName}\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(videoName)\n",
    "    cv2.cv.CaptureFromFile()\n",
    "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    print(f\"{cap.isOpened()}\")\n",
    "\n",
    "    buf = np.empty((frameCount, frameHeight, frameWidth, 3), np.dtype('uint8'))\n",
    "\n",
    "    fc = 0\n",
    "    ret = True\n",
    "    \n",
    "    print(\"[CV2] Started filling Buffer.\")\n",
    "    \n",
    "    while (fc < frameCount and ret):\n",
    "        print(f\"Inside While loop: {fc}\")\n",
    "        ret, buf[fc] = cap.read()\n",
    "        fc += 1\n",
    "        \n",
    "    print(\"[CV2] End filling Buffer.\")\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    #cv2.namedWindow('frame 10')\n",
    "    #cv2.imshow('frame 10', buf[9])\n",
    "    \n",
    "    print(\"[CV2] Waiting...\")\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    print(f\"[CV2] Ready to return: {buf}\")\n",
    "    \n",
    "    return buf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "---\n",
    "\n",
    "In the cells below, first some methods to generate the Noise needed for the GAN is defined, then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Utilities'''\n",
    "def trim(video):\n",
    "    start = np.random.randint(0, video.shape[1] - (T+1))\n",
    "    end = start + T\n",
    "    return video[:, start:end, :, :]\n",
    "\n",
    "# for input noises to generate fake video\n",
    "# note that noises are trimmed randomly from n_frames to T for efficiency\n",
    "def trim_noise(noise):\n",
    "    #print(\"-----TRIMMING NOISE-----\")\n",
    "    #print(f\"Noise Size: {noise.size()}\")\n",
    "    start = np.random.randint(0, noise.size(1) - (T+1))\n",
    "    end = start + T\n",
    "    #print(\"-----END OF TRIMMING NOISE-----\")\n",
    "    return noise[:, start:end, :, :, :]\n",
    "\n",
    "\n",
    "''' calc grad of models '''\n",
    "\n",
    "def bp_i(inputs, y, retain=False):\n",
    "    label = (torch.FloatTensor()).cuda()\n",
    "    label.resize_(inputs.size(0)).fill_(y)\n",
    "    labelv = Variable(label)\n",
    "    outputs = dis_i(inputs)\n",
    "    err = criterion(outputs, labelv)\n",
    "    err.backward(retain_graph=retain)\n",
    "    toReturnErr = err.data[0] if err.size() == torch.Tensor().size() else err.item()\n",
    "    return toReturnErr, outputs.data.mean()\n",
    "\n",
    "def bp_v(inputs, y, retain=False):\n",
    "    #print(\"----BackPropagate_V-----\")\n",
    "    #print(inputs.size())\n",
    "    label = (torch.FloatTensor()).cuda()\n",
    "    try:\n",
    "        label.resize_(inputs.size(0)).fill_(y)\n",
    "\n",
    "    except RuntimeError as _:\n",
    "        # Dimension of y does not allow to use fill_\n",
    "        assert(inputs.size(0) == y.size(0))\n",
    "        label = (torch.FloatTensor(y)).cuda()\n",
    "\n",
    "    labelv = Variable(label)\n",
    "    outputs = dis_v(inputs)\n",
    "    err = criterion(outputs, labelv)\n",
    "    err.backward(retain_graph=retain)\n",
    "    toReturnErr = err.data[0] if err.size() == torch.Tensor().size() else err.item()\n",
    "    #print(\"----End of BackPropagate_V-----\")\n",
    "    return toReturnErr, outputs.data.mean()\n",
    "\n",
    "\n",
    "''' gen input noise for fake video '''\n",
    "\n",
    "def gen_z(n_frames, batch_size = batch_size):\n",
    "    #print(\"----Generating Z-----\")\n",
    "    #print(f\"N_FRAMES: {n_frames}\")\n",
    "    #print(f\"BATCH_SIZE: {batch_size}\")\n",
    "    #print(f\"D_C: {d_C}\")\n",
    "    #print(f\"D_E: {d_E}\")\n",
    "    #print(f\"nz: {nz}\")\n",
    "    z_C = Variable(torch.randn(batch_size, d_C))\n",
    "    #  repeat z_C to (batch_size, n_frames, d_C)\n",
    "    z_C = z_C.unsqueeze(1).repeat(1, n_frames, 1)\n",
    "    eps = Variable(torch.randn(batch_size, d_E))\n",
    "    if cuda == True:\n",
    "        z_C, eps = z_C.cuda(), eps.cuda()\n",
    "\n",
    "    gru.initHidden(batch_size)\n",
    "    # notice that 1st dim of gru outputs is seq_len, 2nd is batch_size\n",
    "    z_M = gru(eps, n_frames).transpose(1, 0)\n",
    "    z = torch.cat((z_M, z_C), 2)  # z.size() => (batch_size, n_frames, nz)\n",
    "    #print(\"----End Generating Z-----\")\n",
    "    return z.view(batch_size, n_frames, nz, 1, 1)\n",
    "\n",
    "''' prepare for train '''\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    d = math.floor(s / ((60**2)*24))\n",
    "    h = math.floor(s / (60**2)) - d*24\n",
    "    m = math.floor(s / 60) - h*60 - d*24*60\n",
    "    s = s - m*60 - h*(60**2) - d*24*(60**2)\n",
    "    return '%dd %dh %dm %ds' % (d, h, m, s)\n",
    "\n",
    "trained_path = os.path.join(current_path, \"mocogan\", 'trained_models')\n",
    "def checkpoint(model, optimizer, epoch):\n",
    "    filename = os.path.join(trained_path, '%s_epoch-%d' % (model.__class__.__name__, epoch))\n",
    "    torch.save(model.state_dict(), filename + '.model')\n",
    "    torch.save(optimizer.state_dict(), filename + '.state')\n",
    "\n",
    "def save_video(fake_video, epoch, runtimeError = False):\n",
    "    outputdata = fake_video * 255\n",
    "    outputdata = outputdata.astype(np.uint8)\n",
    "    dir_path = os.path.join(current_path, 'mocogan', 'generated_videos')\n",
    "    file_path = os.path.join(dir_path, 'fakeVideo_epoch-%d-%s.mp4' % (epoch, \"RuntimeError\" if runtimeError else \"\"))\n",
    "    skvideo.io.vwrite(file_path, outputdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' train models '''\n",
    "def train():\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Starting training: CUDA is { 'On' if cuda == True else 'Off'}\")\n",
    "\n",
    "    for epoch in range(1, n_iter+1):\n",
    "        ''' prepare real images '''\n",
    "        # real_videos.size() => (batch_size, nc, T, img_size, img_size)\n",
    "\n",
    "        # Get data iterator\n",
    "        data_iter = iter(dataloader) #Iterator\n",
    "        data_len = len(dataloader) #Num Batches\n",
    "        data_i = 0\n",
    "\n",
    "        processedClass = None\n",
    "\n",
    "        while data_i < data_len:\n",
    "\n",
    "            try:\n",
    "                #batch_size = 16\n",
    "                (real_videos, labels) = next(data_iter) #random_choice()\n",
    "\n",
    "                ''' Process 1 video for each class while testing. '''\n",
    "                #if (labels in processedClass):\n",
    "                #    continue\n",
    "\n",
    "                #else:\n",
    "                #    processedClass.append(labels)\n",
    "                ''' Process only 1 video class'''\n",
    "                #if processedClass is None:\n",
    "                #    processedClass = labels.item()\n",
    "                #else:\n",
    "                #    if processedClass != labels.item():\n",
    "                #        continue\n",
    "\n",
    "                for (key, val) in dictClassesIdx.items():\n",
    "                    if ( val in labels.tolist() ):\n",
    "                        pass\n",
    "                        #print(key)\n",
    "\n",
    "                if cuda == True:\n",
    "                    real_videos = real_videos.cuda()\n",
    "\n",
    "                real_videos = Variable(real_videos)\n",
    "                real_img = real_videos[:, :, np.random.randint(0, T), :, :]\n",
    "\n",
    "                ''' prepare fake images '''\n",
    "                # note that n_frames is sampled from video length distribution\n",
    "                n_frames = T + 2 + np.random.randint(0, real_videos.size()[2]) #video_lengths[np.random.randint(0, n_videos)]\n",
    "                Z = gen_z(n_frames, batch_size)  # Z.size() => (batch_size, n_frames, nz, 1, 1)\n",
    "                # trim => (batch_size, T, nz, 1, 1)\n",
    "                Z = trim_noise(Z)\n",
    "                # generate videos\n",
    "                Z = Z.contiguous().view(batch_size*T, nz, 1, 1)\n",
    "                fake_videos = gen_i(Z)\n",
    "                fake_videos = fake_videos.view(batch_size, T, nc, img_size, img_size)\n",
    "                # transpose => (batch_size, nc, T, img_size, img_size)\n",
    "                fake_videos = fake_videos.transpose(2, 1)\n",
    "                # img sampling\n",
    "                fake_img = fake_videos[:, :, np.random.randint(0, T), :, :]\n",
    "\n",
    "                ''' train discriminators '''\n",
    "                # video\n",
    "                dis_v.zero_grad()\n",
    "                randomStartFrameIdx = np.random.randint(0, real_videos.size()[2] - T - 1)\n",
    "                #print(\"-----INFOS-----\")\n",
    "                #print(f\"RandomStartFrame:{randomStartFrameIdx}\")\n",
    "                #print(f\"Video Size:{real_videos.size()}\")\n",
    "                #print(\"-----END OF INFOS-----\")\n",
    "                croppedRealVideos = real_videos[:,:,randomStartFrameIdx: randomStartFrameIdx + T, :, :]\n",
    "                #err_Dv_real, Dv_real_mean = bp_v(croppedRealVideos, 0.9)\n",
    "                err_Dv_real, Dv_real_mean = bp_v(croppedRealVideos, labels.type(torch.FloatTensor) / len(dictClassesIdx))\n",
    "                err_Dv_fake, Dv_fake_mean = bp_v(fake_videos.detach(), 0)\n",
    "                err_Dv = err_Dv_real + err_Dv_fake\n",
    "                optim_Dv.step()\n",
    "                # image\n",
    "                dis_i.zero_grad()\n",
    "                err_Di_real, Di_real_mean = bp_i(real_img, 0.9)\n",
    "                err_Di_fake, Di_fake_mean = bp_i(fake_img.detach(), 0)\n",
    "                err_Di = err_Di_real + err_Di_fake\n",
    "                optim_Di.step()\n",
    "\n",
    "\n",
    "                ''' train generators '''\n",
    "                gen_i.zero_grad()\n",
    "                gru.zero_grad()\n",
    "                # video. notice retain=True for back prop twice\n",
    "                err_Gv, _ = bp_v(fake_videos, 0.9, retain=True)\n",
    "                # images\n",
    "                err_Gi, _ = bp_i(fake_img, 0.9)\n",
    "                optim_Gi.step()\n",
    "                optim_GRU.step()\n",
    "\n",
    "                '''Increment index for Batch'''\n",
    "                data_i = data_i + 1\n",
    "            except StopIteration:\n",
    "                break\n",
    "          \n",
    "            except RuntimeError:\n",
    "                print(\"Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\")\n",
    "                epoch = epoch - 1\n",
    "                save_video(fake_videos[0].data.cpu().numpy().transpose(1, 2, 3, 0), epoch, True)\n",
    "                break\n",
    "          \n",
    "            except KeyboardInterrupt:\n",
    "                save_video(fake_videos[0].data.cpu().numpy().transpose(1, 2, 3, 0), epoch)\n",
    "                checkpoint(dis_i, optim_Di, epoch)\n",
    "                checkpoint(dis_v, optim_Dv, epoch)\n",
    "                checkpoint(gen_i, optim_Gi, epoch)\n",
    "                checkpoint(gru,   optim_GRU, epoch)\n",
    "\n",
    "\n",
    "        if epoch % n_epochs_display == 0:\n",
    "            print('[%d/%d] (%s) Loss_Di: %.4f Loss_Dv: %.4f Loss_Gi: %.4f Loss_Gv: %.4f Di_real_mean %.4f Di_fake_mean %.4f Dv_real_mean %.4f Dv_fake_mean %.4f'\n",
    "                  % (epoch, n_iter, timeSince(start_time), err_Di, err_Dv, err_Gi, err_Gv, Di_real_mean, Di_fake_mean, Dv_real_mean, Dv_fake_mean))\n",
    "\n",
    "        if epoch % n_epochs_saveV == 0:\n",
    "            save_video(fake_videos[0].data.cpu().numpy().transpose(1, 2, 3, 0), epoch)\n",
    "\n",
    "        if epoch % n_epochs_check == 0:\n",
    "            checkpoint(dis_i, optim_Di, epoch)\n",
    "            checkpoint(dis_v, optim_Dv, epoch)\n",
    "            checkpoint(gen_i, optim_Gi, epoch)\n",
    "            checkpoint(gru,   optim_GRU, epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Previous State\n",
    "---\n",
    "If wanted, the following cell can be used to load the previous state of a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' use pre-trained models '''\n",
    "\n",
    "def load():\n",
    "    dis_i.load_state_dict(torch.load(trained_path + '/Discriminator_I.model'))\n",
    "    dis_v.load_state_dict(torch.load(trained_path + '/Discriminator_V.model'))\n",
    "    gen_i.load_state_dict(torch.load(trained_path + '/Generator_I.model'))\n",
    "    gru.load_state_dict(torch.load(trained_path + '/GRU.model'))\n",
    "    optim_Di.load_state_dict(torch.load(trained_path + '/Discriminator_I.state'))\n",
    "    optim_Dv.load_state_dict(torch.load(trained_path + '/Discriminator_V.state'))\n",
    "    optim_Gi.load_state_dict(torch.load(trained_path + '/Generator_I.state'))\n",
    "    optim_GRU.load_state_dict(torch.load(trained_path + '/GRU.state'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, start training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training: CUDA is On\n",
      "[1/120000] (0d 0h 12m 56s) Loss_Di: 0.5370 Loss_Dv: 0.6628 Loss_Gi: 2.8111 Loss_Gv: 3.6682 Di_real_mean 0.6619 Di_fake_mean 0.0081 Dv_real_mean 0.5586 Dv_fake_mean 0.0275\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[1/120000] (0d 0h 13m 9s) Loss_Di: 0.6135 Loss_Dv: 0.6477 Loss_Gi: 4.0602 Loss_Gv: 3.8416 Di_real_mean 0.9703 Di_fake_mean 0.1787 Dv_real_mean 0.5033 Dv_fake_mean 0.0174\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[2/120000] (0d 0h 20m 59s) Loss_Di: 0.4095 Loss_Dv: 0.6575 Loss_Gi: 3.2490 Loss_Gv: 3.0582 Di_real_mean 0.9023 Di_fake_mean 0.0521 Dv_real_mean 0.4654 Dv_fake_mean 0.0335\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[3/120000] (0d 0h 22m 35s) Loss_Di: 0.4623 Loss_Dv: 0.6143 Loss_Gi: 2.6604 Loss_Gv: 4.0631 Di_real_mean 0.7295 Di_fake_mean 0.0256 Dv_real_mean 0.5794 Dv_fake_mean 0.0168\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[4/120000] (0d 0h 24m 7s) Loss_Di: 0.5601 Loss_Dv: 0.6859 Loss_Gi: 3.7832 Loss_Gv: 4.0793 Di_real_mean 0.9748 Di_fake_mean 0.1276 Dv_real_mean 0.5777 Dv_fake_mean 0.0241\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[5/120000] (0d 0h 25m 42s) Loss_Di: 0.4157 Loss_Dv: 0.6622 Loss_Gi: 3.7725 Loss_Gv: 3.9673 Di_real_mean 0.8444 Di_fake_mean 0.0346 Dv_real_mean 0.4612 Dv_fake_mean 0.0141\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[6/120000] (0d 0h 28m 46s) Loss_Di: 0.4918 Loss_Dv: 0.6001 Loss_Gi: 4.5952 Loss_Gv: 4.3545 Di_real_mean 0.9636 Di_fake_mean 0.0831 Dv_real_mean 0.5830 Dv_fake_mean 0.0120\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[7/120000] (0d 0h 30m 24s) Loss_Di: 0.3881 Loss_Dv: 0.6467 Loss_Gi: 4.9537 Loss_Gv: 3.9165 Di_real_mean 0.9464 Di_fake_mean 0.0212 Dv_real_mean 0.5376 Dv_fake_mean 0.0322\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[8/120000] (0d 0h 31m 50s) Loss_Di: 0.4684 Loss_Dv: 0.7012 Loss_Gi: 3.5106 Loss_Gv: 3.2736 Di_real_mean 0.7294 Di_fake_mean 0.0139 Dv_real_mean 0.5950 Dv_fake_mean 0.0630\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[9/120000] (0d 0h 38m 14s) Loss_Di: 0.4034 Loss_Dv: 0.7161 Loss_Gi: 3.0040 Loss_Gv: 4.0609 Di_real_mean 0.8103 Di_fake_mean 0.0215 Dv_real_mean 0.6048 Dv_fake_mean 0.0500\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[10/120000] (0d 0h 39m 45s) Loss_Di: 0.4311 Loss_Dv: 0.6003 Loss_Gi: 4.1859 Loss_Gv: 3.5589 Di_real_mean 0.7641 Di_fake_mean 0.0066 Dv_real_mean 0.4570 Dv_fake_mean 0.0254\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[11/120000] (0d 0h 41m 15s) Loss_Di: 0.4056 Loss_Dv: 0.6801 Loss_Gi: 3.5715 Loss_Gv: 3.9508 Di_real_mean 0.8584 Di_fake_mean 0.0428 Dv_real_mean 0.5008 Dv_fake_mean 0.0338\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[12/120000] (0d 0h 42m 52s) Loss_Di: 0.4740 Loss_Dv: 0.6201 Loss_Gi: 4.0983 Loss_Gv: 4.6513 Di_real_mean 0.7180 Di_fake_mean 0.0178 Dv_real_mean 0.4869 Dv_fake_mean 0.0079\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[13/120000] (0d 0h 44m 23s) Loss_Di: 0.4168 Loss_Dv: 0.7231 Loss_Gi: 3.9115 Loss_Gv: 4.1039 Di_real_mean 0.9310 Di_fake_mean 0.0453 Dv_real_mean 0.5928 Dv_fake_mean 0.0344\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[14/120000] (0d 0h 53m 55s) Loss_Di: 0.4599 Loss_Dv: 0.6563 Loss_Gi: 3.3443 Loss_Gv: 4.4450 Di_real_mean 0.7580 Di_fake_mean 0.0129 Dv_real_mean 0.6303 Dv_fake_mean 0.0286\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[15/120000] (0d 1h 1m 54s) Loss_Di: 0.5511 Loss_Dv: 0.6244 Loss_Gi: 3.9116 Loss_Gv: 4.4232 Di_real_mean 0.9818 Di_fake_mean 0.0947 Dv_real_mean 0.4195 Dv_fake_mean 0.0113\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[16/120000] (0d 1h 3m 28s) Loss_Di: 0.4573 Loss_Dv: 0.7097 Loss_Gi: 4.5110 Loss_Gv: 3.9605 Di_real_mean 0.8889 Di_fake_mean 0.0758 Dv_real_mean 0.5519 Dv_fake_mean 0.0713\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[17/120000] (0d 1h 11m 26s) Loss_Di: 0.4423 Loss_Dv: 0.6388 Loss_Gi: 3.5956 Loss_Gv: 4.2976 Di_real_mean 0.8138 Di_fake_mean 0.0243 Dv_real_mean 0.5040 Dv_fake_mean 0.0186\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[18/120000] (0d 1h 13m 0s) Loss_Di: 0.4459 Loss_Dv: 0.6788 Loss_Gi: 4.3561 Loss_Gv: 5.3262 Di_real_mean 0.9082 Di_fake_mean 0.0644 Dv_real_mean 0.5646 Dv_fake_mean 0.0162\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[19/120000] (0d 1h 19m 19s) Loss_Di: 0.6523 Loss_Dv: 0.8744 Loss_Gi: 4.6454 Loss_Gv: 2.1777 Di_real_mean 0.9706 Di_fake_mean 0.2039 Dv_real_mean 0.2639 Dv_fake_mean 0.0228\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[20/120000] (0d 1h 22m 29s) Loss_Di: 0.4944 Loss_Dv: 0.6171 Loss_Gi: 4.3824 Loss_Gv: 3.9732 Di_real_mean 0.9411 Di_fake_mean 0.1100 Dv_real_mean 0.4367 Dv_fake_mean 0.0160\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[21/120000] (0d 1h 25m 34s) Loss_Di: 0.5621 Loss_Dv: 0.7970 Loss_Gi: 2.7651 Loss_Gv: 4.1327 Di_real_mean 0.6690 Di_fake_mean 0.0225 Dv_real_mean 0.6943 Dv_fake_mean 0.0589\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[22/120000] (0d 1h 33m 41s) Loss_Di: 0.4133 Loss_Dv: 0.6761 Loss_Gi: 3.8111 Loss_Gv: 3.0378 Di_real_mean 0.9243 Di_fake_mean 0.0447 Dv_real_mean 0.4963 Dv_fake_mean 0.0665\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[23/120000] (0d 1h 41m 33s) Loss_Di: 0.3958 Loss_Dv: 0.6564 Loss_Gi: 4.5743 Loss_Gv: 3.5056 Di_real_mean 0.9097 Di_fake_mean 0.0417 Dv_real_mean 0.5789 Dv_fake_mean 0.0787\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[24/120000] (0d 1h 46m 32s) Loss_Di: 0.4168 Loss_Dv: 0.5835 Loss_Gi: 5.1214 Loss_Gv: 3.4157 Di_real_mean 0.9604 Di_fake_mean 0.0306 Dv_real_mean 0.3868 Dv_fake_mean 0.0166\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[25/120000] (0d 1h 49m 30s) Loss_Di: 0.3911 Loss_Dv: 0.6778 Loss_Gi: 4.6608 Loss_Gv: 3.7410 Di_real_mean 0.8462 Di_fake_mean 0.0160 Dv_real_mean 0.6274 Dv_fake_mean 0.0498\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[26/120000] (0d 1h 52m 52s) Loss_Di: 0.4639 Loss_Dv: 0.6122 Loss_Gi: 2.5939 Loss_Gv: 4.3322 Di_real_mean 0.8341 Di_fake_mean 0.0520 Dv_real_mean 0.5441 Dv_fake_mean 0.0307\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[27/120000] (0d 1h 54m 16s) Loss_Di: 0.5318 Loss_Dv: 0.5581 Loss_Gi: 3.9951 Loss_Gv: 4.5657 Di_real_mean 0.9120 Di_fake_mean 0.1320 Dv_real_mean 0.4247 Dv_fake_mean 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[28/120000] (0d 1h 55m 57s) Loss_Di: 0.4283 Loss_Dv: 0.6676 Loss_Gi: 3.0008 Loss_Gv: 4.5849 Di_real_mean 0.8487 Di_fake_mean 0.0395 Dv_real_mean 0.4923 Dv_fake_mean 0.0224\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[29/120000] (0d 1h 57m 18s) Loss_Di: 0.5321 Loss_Dv: 0.6264 Loss_Gi: 2.6851 Loss_Gv: 4.3746 Di_real_mean 0.6793 Di_fake_mean 0.0159 Dv_real_mean 0.4624 Dv_fake_mean 0.0183\n",
      "Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\n",
      "[30/120000] (0d 2h 0m 37s) Loss_Di: 0.4296 Loss_Dv: 0.6202 Loss_Gi: 3.1150 Loss_Gv: 3.9602 Di_real_mean 0.8205 Di_fake_mean 0.0246 Dv_real_mean 0.4762 Dv_fake_mean 0.0337\n"
     ]
    }
   ],
   "source": [
    "load()\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

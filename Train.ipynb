{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of MoCoGAN\n",
    "---\n",
    "In this Notebook is covered the topic of training the MoCoGAN and the fine tuning of this network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining global variables and imports\n",
    "---\n",
    "In the below cell all of the imports that are needed to the training and some global variables like `device` to use the GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import skvideo.io\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim, cuda as cu, device, manual_seed\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import DatasetFolder\n",
    "from torchvision.transforms import Lambda, Compose\n",
    "\n",
    "'''Import variables from train.py'''\n",
    "img_size = 96\n",
    "nc = 3\n",
    "ndf = 64 # from dcgan\n",
    "ngf = 64\n",
    "d_E = 10\n",
    "hidden_size = 100 # guess\n",
    "d_C = 50\n",
    "d_M = d_E\n",
    "nz  = d_C + d_M\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "T = 16 # Hyperparameter for taking #Frames into discriminator.\n",
    "\n",
    "ngpu       = 1\n",
    "batch_size = 32\n",
    "n_iter     = 120000\n",
    "pre_train  = False\n",
    "\n",
    "## Addition for training on UCF-101\n",
    "n_epochs_saveV      = 5\n",
    "n_epochs_display    = 1\n",
    "n_epochs_check      = 5\n",
    "max_frame           = 25\n",
    "cuda                = True #For compatibility with old version of MocoGan\n",
    "#### End of additions\n",
    "\n",
    "\n",
    "seed = 0\n",
    "manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = device(\"cuda\" if cu.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of Models\n",
    "From the `models` module, let's import all of the models and let's load the previous state for fine tuning.\n",
    "\n",
    "Then models are moved into the device chosen in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"./mocogan/\")\n",
    "from models import Discriminator_I, Discriminator_V, Generator_I ,GRU, UCF_101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./mocogan/models.py:159: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(params)\n",
      "./mocogan/models.py:169: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(params, 0)\n"
     ]
    }
   ],
   "source": [
    "'''Create the objects for Discriminator_(I|V), GRU and Generator_I'''\n",
    "gen_i = Generator_I(nc, ngf, nz, ngpu = 1)\n",
    "gru = GRU(d_E, hidden_size, gpu = cu.is_available())\n",
    "dis_i = Discriminator_I(nc, ndf, ngpu = 1)\n",
    "dis_v = Discriminator_V(nc, ndf, T = T, ngpu = 1)\n",
    "gru.initWeight()\n",
    "\n",
    "'''Move objects into the device chosen'''\n",
    "''' adjust to cuda '''\n",
    "if cuda == True:\n",
    "    dis_i.cuda()\n",
    "    dis_v.cuda()\n",
    "    gen_i.cuda()\n",
    "    gru.cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "'''Optimizer Settings and Optimizer'''\n",
    "lr = 0.0002\n",
    "betas=(0.5, 0.999)\n",
    "optim_Di  = optim.Adam(dis_i.parameters(), lr=lr, betas=betas)\n",
    "optim_Dv  = optim.Adam(dis_v.parameters(), lr=lr, betas=betas)\n",
    "optim_Gi  = optim.Adam(gen_i.parameters(), lr=lr, betas=betas)\n",
    "optim_GRU = optim.Adam(gru.parameters(),   lr=lr, betas=betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "---\n",
    "In the cells below, the dataloader will be defined and also all of the transformation that will be applied to the videos before taking them into a batch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = !pwd\n",
    "current_path = str(current_path[0])\n",
    "resized_path = os.path.join(current_path, \"mocogan\", 'resized_data')\n",
    "files = glob(resized_path+'/*/*')\n",
    "\n",
    "#transformation = Compose([ToTensor(), Lambda(lambda tensor: (tensor - tensor.mean() )/ tensor.std())])\n",
    "\n",
    "transformation = Compose([Lambda(lambda video: video.transpose(3, 0, 1, 2)/255.0),\n",
    "                            Lambda(lambda video: video[ : , : max_frame, :, : ]),\n",
    "                            Lambda(lambda video: torch.FloatTensor(video))])\n",
    "\n",
    "filenameDictClassesIdx = \"classInd.txt\"\n",
    "dictClassesIdx = {}\n",
    "try:\n",
    "    with open(os.path.join(current_path, \"ucfTrainTestlist\", filenameDictClassesIdx)) as file:\n",
    "        for line in file:\n",
    "            dictClassesIdx[ line.split() [1]] = int( line.split() [0] )\n",
    "            \n",
    "except FileNotFoundError as _:\n",
    "    with open(os.path.join(current_path, \"mocogan\", \"ucfTrainTestlist\", filenameDictClassesIdx)) as file:\n",
    "        for line in file:\n",
    "            dictClassesIdx[ line.split() [1]] = int( line.split() [0] )\n",
    "\n",
    "# dataset = DatasetFolder(resized_path, loadVideo, [\"mp4\"], transform= transformation)\n",
    "#dataset = DatasetFolder(resized_path, skvideo.io.vread, [\"mp4\"], transform= transformation)\n",
    "dataset = UCF_101(resized_path, skvideo.io.vread, [\"mp4\"], transform= transformation)\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size= batch_size, shuffle= True, num_workers= 8, pin_memory= True, drop_last= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General configuration for OpenCV 3.1.0 =====================================\n",
      "  Version control:               unknown\n",
      "\n",
      "  Platform:\n",
      "    Host:                        Linux 4.8.12-040812-generic x86_64\n",
      "    CMake:                       3.6.3\n",
      "    CMake generator:             Unix Makefiles\n",
      "    CMake build tool:            /usr/bin/make\n",
      "    Configuration:               Release\n",
      "\n",
      "  C/C++:\n",
      "    Built as dynamic libs?:      YES\n",
      "    C++ Compiler:                /usr/bin/c++  (ver 4.6.3)\n",
      "    C++ flags (Release):         -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -msse -msse2 -mno-avx -msse3 -mno-ssse3 -mno-sse4.1 -mno-sse4.2 -ffunction-sections -fvisibility=hidden -fvisibility-inlines-hidden -fopenmp -O3 -DNDEBUG  -DNDEBUG\n",
      "    C++ flags (Debug):           -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wundef -Winit-self -Wpointer-arith -Wshadow -Wsign-promo -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -msse -msse2 -mno-avx -msse3 -mno-ssse3 -mno-sse4.1 -mno-sse4.2 -ffunction-sections -fvisibility=hidden -fvisibility-inlines-hidden -fopenmp -g  -O0 -DDEBUG -D_DEBUG\n",
      "    C Compiler:                  /usr/bin/cc\n",
      "    C flags (Release):           -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -msse -msse2 -mno-avx -msse3 -mno-ssse3 -mno-sse4.1 -mno-sse4.2 -ffunction-sections -fvisibility=hidden -fopenmp -O3 -DNDEBUG  -DNDEBUG\n",
      "    C flags (Debug):             -fsigned-char -W -Wall -Werror=return-type -Werror=non-virtual-dtor -Werror=address -Werror=sequence-point -Wformat -Werror=format-security -Wmissing-declarations -Wmissing-prototypes -Wstrict-prototypes -Wundef -Winit-self -Wpointer-arith -Wshadow -fdiagnostics-show-option -Wno-long-long -pthread -fomit-frame-pointer -msse -msse2 -mno-avx -msse3 -mno-ssse3 -mno-sse4.1 -mno-sse4.2 -ffunction-sections -fvisibility=hidden -fopenmp -g  -O0 -DDEBUG -D_DEBUG\n",
      "    Linker flags (Release):\n",
      "    Linker flags (Debug):\n",
      "    Precompiled headers:         YES\n",
      "    Extra dependencies:          gtk-x11-2.0 gdk-x11-2.0 atk-1.0 gio-2.0 pangoft2-1.0 pangocairo-1.0 gdk_pixbuf-2.0 cairo pango-1.0 freetype fontconfig gobject-2.0 gthread-2.0 glib-2.0 dl m pthread rt\n",
      "    3rdparty dependencies:       zlib libjpeg libwebp libpng libtiff libjasper IlmImf libprotobuf\n",
      "\n",
      "  OpenCV modules:\n",
      "    To be built:                 core flann imgproc ml photo reg surface_matching video dnn fuzzy imgcodecs shape videoio highgui objdetect plot superres xobjdetect xphoto bgsegm bioinspired dpm face features2d line_descriptor saliency text calib3d ccalib datasets java rgbd stereo structured_light tracking videostab xfeatures2d ximgproc aruco optflow stitching python3\n",
      "    Disabled:                    world contrib_world\n",
      "    Disabled by dependency:      -\n",
      "    Unavailable:                 cudaarithm cudabgsegm cudacodec cudafeatures2d cudafilters cudaimgproc cudalegacy cudaobjdetect cudaoptflow cudastereo cudawarping cudev python2 ts viz cvv hdf matlab sfm\n",
      "\n",
      "  GUI: \n",
      "    QT:                          NO\n",
      "    GTK+ 2.x:                    YES (ver 2.24.10)\n",
      "    GThread :                    YES (ver 2.32.4)\n",
      "    GtkGlExt:                    NO\n",
      "    OpenGL support:              NO\n",
      "    VTK support:                 NO\n",
      "\n",
      "  Media I/O: \n",
      "    ZLib:                        build (ver 1.2.8)\n",
      "    JPEG:                        build (ver 90)\n",
      "    WEBP:                        build (ver 0.3.1)\n",
      "    PNG:                         build (ver 1.6.19)\n",
      "    TIFF:                        build (ver 42 - 4.0.2)\n",
      "    JPEG 2000:                   build (ver 1.900.1)\n",
      "    OpenEXR:                     build (ver 1.7.1)\n",
      "    GDAL:                        NO\n",
      "\n",
      "  Video I/O:\n",
      "    DC1394 1.x:                  NO\n",
      "    DC1394 2.x:                  NO\n",
      "    FFMPEG:                      NO\n",
      "      codec:                     NO\n",
      "      format:                    NO\n",
      "      util:                      NO\n",
      "      swscale:                   NO\n",
      "      resample:                  NO\n",
      "      gentoo-style:              NO\n",
      "    GStreamer:                   NO\n",
      "    OpenNI:                      NO\n",
      "    OpenNI PrimeSensor Modules:  NO\n",
      "    OpenNI2:                     NO\n",
      "    PvAPI:                       NO\n",
      "    GigEVisionSDK:               NO\n",
      "    UniCap:                      NO\n",
      "    UniCap ucil:                 NO\n",
      "    V4L/V4L2:                    NO/YES\n",
      "    XIMEA:                       NO\n",
      "    Xine:                        NO\n",
      "    gPhoto2:                     NO\n",
      "\n",
      "  Parallel framework:            OpenMP\n",
      "\n",
      "  Other third-party libraries:\n",
      "    Use IPP:                     9.0.1 [9.0.1]\n",
      "         at:                     /home/travis/miniconda/conda-bld/conda_1486587069159/work/opencv-3.1.0/3rdparty/ippicv/unpack/ippicv_lnx\n",
      "    Use IPP Async:               NO\n",
      "    Use VA:                      NO\n",
      "    Use Intel VA-API/OpenCL:     NO\n",
      "    Use Eigen:                   YES (ver 3.2.7)\n",
      "    Use Cuda:                    NO\n",
      "    Use OpenCL:                  NO\n",
      "    Use custom HAL:              NO\n",
      "\n",
      "  Python 2:\n",
      "    Interpreter:                 /usr/bin/python2.7 (ver 2.7.3)\n",
      "\n",
      "  Python 3:\n",
      "    Interpreter:                 /home/carlo/anaconda3/bin/python (ver 3.6)\n",
      "    Libraries:                   /home/carlo/anaconda3/lib/libpython3.6m.so (ver 3.6.0)\n",
      "    numpy:                       /home/carlo/anaconda3/lib/python3.6/site-packages/numpy/core/include (ver 1.11.3)\n",
      "    packages path:               lib/python3.6/site-packages\n",
      "\n",
      "  Python (for build):            /usr/bin/python2.7\n",
      "\n",
      "  Java:\n",
      "    ant:                         /usr/bin/ant (ver 1.8.2)\n",
      "    JNI:                         /usr/lib/jvm/java-7-openjdk-amd64/include /usr/lib/jvm/java-7-openjdk-amd64/include /usr/lib/jvm/java-7-openjdk-amd64/include\n",
      "    Java wrappers:               YES\n",
      "    Java tests:                  NO\n",
      "\n",
      "  Matlab:                        Matlab not found or implicitly disabled\n",
      "\n",
      "  Tests and samples:\n",
      "    Tests:                       NO\n",
      "    Performance tests:           NO\n",
      "    C/C++ Examples:              NO\n",
      "\n",
      "  Install path:                  /home/carlo/anaconda3\n",
      "\n",
      "  cvconfig.h is in:              /home/travis/miniconda/conda-bld/conda_1486587069159/work/opencv-3.1.0/build\n",
      "-----------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "print( cv2.getBuildInformation() )\n",
    "\n",
    "def loadVideo(videoName):    \n",
    "    print(f\"[CV2] Loading : {videoName}\")\n",
    "    \n",
    "    cap = cv2.VideoCapture(videoName)\n",
    "    cv2.cv.CaptureFromFile()\n",
    "    frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    print(f\"{cap.isOpened()}\")\n",
    "\n",
    "    buf = np.empty((frameCount, frameHeight, frameWidth, 3), np.dtype('uint8'))\n",
    "\n",
    "    fc = 0\n",
    "    ret = True\n",
    "    \n",
    "    print(\"[CV2] Started filling Buffer.\")\n",
    "    \n",
    "    while (fc < frameCount and ret):\n",
    "        print(f\"Inside While loop: {fc}\")\n",
    "        ret, buf[fc] = cap.read()\n",
    "        fc += 1\n",
    "        \n",
    "    print(\"[CV2] End filling Buffer.\")\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    #cv2.namedWindow('frame 10')\n",
    "    #cv2.imshow('frame 10', buf[9])\n",
    "    \n",
    "    print(\"[CV2] Waiting...\")\n",
    "\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "    print(f\"[CV2] Ready to return: {buf}\")\n",
    "    \n",
    "    return buf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "---\n",
    "\n",
    "In the cells below, first some methods to generate the Noise needed for the GAN is defined, then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Utilities'''\n",
    "def trim(video):\n",
    "    start = np.random.randint(0, video.shape[1] - (T+1))\n",
    "    end = start + T\n",
    "    return video[:, start:end, :, :]\n",
    "\n",
    "# for input noises to generate fake video\n",
    "# note that noises are trimmed randomly from n_frames to T for efficiency\n",
    "def trim_noise(noise):\n",
    "    #print(\"-----TRIMMING NOISE-----\")\n",
    "    #print(f\"Noise Size: {noise.size()}\")\n",
    "    start = np.random.randint(0, noise.size(1) - (T+1))\n",
    "    end = start + T\n",
    "    #print(\"-----END OF TRIMMING NOISE-----\")\n",
    "    return noise[:, start:end, :, :, :]\n",
    "\n",
    "\n",
    "''' calc grad of models '''\n",
    "\n",
    "def bp_i(inputs, y, retain=False):\n",
    "    label = (torch.FloatTensor()).cuda()\n",
    "    label.resize_(inputs.size(0)).fill_(y)\n",
    "    labelv = Variable(label)\n",
    "    outputs = dis_i(inputs)\n",
    "    err = criterion(outputs, labelv)\n",
    "    err.backward(retain_graph=retain)\n",
    "    toReturnErr = err.data[0] if err.size() == torch.Tensor().size() else err.item()\n",
    "    return toReturnErr, outputs.data.mean()\n",
    "\n",
    "def bp_v(inputs, y, retain=False):\n",
    "    #print(\"----BackPropagate_V-----\")\n",
    "    #print(inputs.size())\n",
    "    label = (torch.FloatTensor()).cuda()\n",
    "    try:\n",
    "        label.resize_(inputs.size(0)).fill_(y)\n",
    "\n",
    "    except RuntimeError as _:\n",
    "        # Dimension of y does not allow to use fill_\n",
    "        assert(inputs.size(0) == y.size(0))\n",
    "        label = (torch.FloatTensor(y)).cuda()\n",
    "\n",
    "    labelv = Variable(label)\n",
    "    outputs = dis_v(inputs)\n",
    "    err = criterion(outputs, labelv)\n",
    "    err.backward(retain_graph=retain)\n",
    "    toReturnErr = err.data[0] if err.size() == torch.Tensor().size() else err.item()\n",
    "    #print(\"----End of BackPropagate_V-----\")\n",
    "    return toReturnErr, outputs.data.mean()\n",
    "\n",
    "\n",
    "''' gen input noise for fake video '''\n",
    "\n",
    "def gen_z(n_frames, batch_size = batch_size):\n",
    "    #print(\"----Generating Z-----\")\n",
    "    #print(f\"N_FRAMES: {n_frames}\")\n",
    "    #print(f\"BATCH_SIZE: {batch_size}\")\n",
    "    #print(f\"D_C: {d_C}\")\n",
    "    #print(f\"D_E: {d_E}\")\n",
    "    #print(f\"nz: {nz}\")\n",
    "    z_C = Variable(torch.randn(batch_size, d_C))\n",
    "    #  repeat z_C to (batch_size, n_frames, d_C)\n",
    "    z_C = z_C.unsqueeze(1).repeat(1, n_frames, 1)\n",
    "    eps = Variable(torch.randn(batch_size, d_E))\n",
    "    if cuda == True:\n",
    "        z_C, eps = z_C.cuda(), eps.cuda()\n",
    "\n",
    "    gru.initHidden(batch_size)\n",
    "    # notice that 1st dim of gru outputs is seq_len, 2nd is batch_size\n",
    "    z_M = gru(eps, n_frames).transpose(1, 0)\n",
    "    z = torch.cat((z_M, z_C), 2)  # z.size() => (batch_size, n_frames, nz)\n",
    "    #print(\"----End Generating Z-----\")\n",
    "    return z.view(batch_size, n_frames, nz, 1, 1)\n",
    "\n",
    "''' prepare for train '''\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    d = math.floor(s / ((60**2)*24))\n",
    "    h = math.floor(s / (60**2)) - d*24\n",
    "    m = math.floor(s / 60) - h*60 - d*24*60\n",
    "    s = s - m*60 - h*(60**2) - d*24*(60**2)\n",
    "    return '%dd %dh %dm %ds' % (d, h, m, s)\n",
    "\n",
    "trained_path = os.path.join(current_path, \"mocogan\", 'trained_models')\n",
    "def checkpoint(model, optimizer, epoch):\n",
    "    filename = os.path.join(trained_path, '%s_epoch-%d' % (model.__class__.__name__, epoch))\n",
    "    torch.save(model.state_dict(), filename + '.model')\n",
    "    torch.save(optimizer.state_dict(), filename + '.state')\n",
    "\n",
    "def save_video(fake_video, epoch, runtimeError = False):\n",
    "    outputdata = fake_video * 255\n",
    "    outputdata = outputdata.astype(np.uint8)\n",
    "    dir_path = os.path.join(current_path, 'mocogan', 'generated_videos')\n",
    "    file_path = os.path.join(dir_path, 'fakeVideo_epoch-%d-%s.mp4' % (epoch, \"RuntimeError\" if runtimeError else \"\"))\n",
    "    skvideo.io.vwrite(file_path, outputdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nexcept RuntimeError:\\n    print(\"Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\")\\n    epoch = epoch - 1\\n    save_video(fake_videos[0].data.cpu().numpy().transpose(1, 2, 3, 0), epoch, True)\\n    break\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' train models '''\n",
    "def train():\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Starting training: CUDA is { 'On' if cuda == True else 'Off'}\")\n",
    "\n",
    "    for epoch in range(1, n_iter+1):\n",
    "        ''' prepare real images '''\n",
    "        # real_videos.size() => (batch_size, nc, T, img_size, img_size)\n",
    "\n",
    "        # Get data iterator\n",
    "        data_iter = iter(dataloader) #Iterator\n",
    "        data_len = len(dataloader) #Num Batches\n",
    "        data_i = 0\n",
    "\n",
    "        processedClass = None\n",
    "\n",
    "        while data_i < data_len:\n",
    "\n",
    "            try:\n",
    "                #batch_size = 16\n",
    "                (real_videos, labels) = next(data_iter) #random_choice()\n",
    "\n",
    "                ''' Process 1 video for each class while testing. '''\n",
    "                #if (labels in processedClass):\n",
    "                #    continue\n",
    "\n",
    "                #else:\n",
    "                #    processedClass.append(labels)\n",
    "                ''' Process only 1 video class'''\n",
    "                #if processedClass is None:\n",
    "                #    processedClass = labels.item()\n",
    "                #else:\n",
    "                #    if processedClass != labels.item():\n",
    "                #        continue\n",
    "\n",
    "                for (key, val) in dictClassesIdx.items():\n",
    "                    if ( val in labels.tolist() ):\n",
    "                        pass\n",
    "                        #print(key)\n",
    "\n",
    "                if cuda == True:\n",
    "                    real_videos = real_videos.cuda()\n",
    "\n",
    "                real_videos = Variable(real_videos)\n",
    "                real_img = real_videos[:, :, np.random.randint(0, T), :, :]\n",
    "\n",
    "                ''' prepare fake images '''\n",
    "                # note that n_frames is sampled from video length distribution\n",
    "                n_frames = T + 2 + np.random.randint(0, real_videos.size()[2]) #video_lengths[np.random.randint(0, n_videos)]\n",
    "                Z = gen_z(n_frames, batch_size)  # Z.size() => (batch_size, n_frames, nz, 1, 1)\n",
    "                # trim => (batch_size, T, nz, 1, 1)\n",
    "                Z = trim_noise(Z)\n",
    "                # generate videos\n",
    "                Z = Z.contiguous().view(batch_size*T, nz, 1, 1)\n",
    "                fake_videos = gen_i(Z)\n",
    "                fake_videos = fake_videos.view(batch_size, T, nc, img_size, img_size)\n",
    "                # transpose => (batch_size, nc, T, img_size, img_size)\n",
    "                fake_videos = fake_videos.transpose(2, 1)\n",
    "                # img sampling\n",
    "                fake_img = fake_videos[:, :, np.random.randint(0, T), :, :]\n",
    "\n",
    "                ''' train discriminators '''\n",
    "                # video\n",
    "                dis_v.zero_grad()\n",
    "                randomStartFrameIdx = np.random.randint(0, real_videos.size()[2] - T - 1)\n",
    "                #print(\"-----INFOS-----\")\n",
    "                #print(f\"RandomStartFrame:{randomStartFrameIdx}\")\n",
    "                #print(f\"Video Size:{real_videos.size()}\")\n",
    "                #print(\"-----END OF INFOS-----\")\n",
    "                croppedRealVideos = real_videos[:,:,randomStartFrameIdx: randomStartFrameIdx + T, :, :]\n",
    "                #err_Dv_real, Dv_real_mean = bp_v(croppedRealVideos, 0.9)\n",
    "                err_Dv_real, Dv_real_mean = bp_v(croppedRealVideos, labels.type(torch.FloatTensor) / len(dictClassesIdx))\n",
    "                err_Dv_fake, Dv_fake_mean = bp_v(fake_videos.detach(), 0)\n",
    "                err_Dv = err_Dv_real + err_Dv_fake\n",
    "                optim_Dv.step()\n",
    "                # image\n",
    "                dis_i.zero_grad()\n",
    "                err_Di_real, Di_real_mean = bp_i(real_img, 0.9)\n",
    "                err_Di_fake, Di_fake_mean = bp_i(fake_img.detach(), 0)\n",
    "                err_Di = err_Di_real + err_Di_fake\n",
    "                optim_Di.step()\n",
    "\n",
    "\n",
    "                ''' train generators '''\n",
    "                gen_i.zero_grad()\n",
    "                gru.zero_grad()\n",
    "                # video. notice retain=True for back prop twice\n",
    "                err_Gv, _ = bp_v(fake_videos, 0.9, retain=True)\n",
    "                # images\n",
    "                err_Gi, _ = bp_i(fake_img, 0.9)\n",
    "                optim_Gi.step()\n",
    "                optim_GRU.step()\n",
    "\n",
    "                '''Increment index for Batch'''\n",
    "                data_i = data_i + 1\n",
    "          \n",
    "                time.sleep(1)\n",
    "          \n",
    "            except StopIteration:\n",
    "                break\n",
    "            \n",
    "            except KeyboardInterrupt:\n",
    "                save_video(fake_videos[0].data.cpu().numpy().transpose(1, 2, 3, 0), epoch)\n",
    "                checkpoint(dis_i, optim_Di, epoch)\n",
    "                checkpoint(dis_v, optim_Dv, epoch)\n",
    "                checkpoint(gen_i, optim_Gi, epoch)\n",
    "                checkpoint(gru,   optim_GRU, epoch)\n",
    "\n",
    "        if epoch % n_epochs_display == 0:\n",
    "            print('[%d/%d] (%s) Loss_Di: %.4f Loss_Dv: %.4f Loss_Gi: %.4f Loss_Gv: %.4f Di_real_mean %.4f Di_fake_mean %.4f Dv_real_mean %.4f Dv_fake_mean %.4f'\n",
    "                  % (epoch, n_iter, timeSince(start_time), err_Di, err_Dv, err_Gi, err_Gv, Di_real_mean, Di_fake_mean, Dv_real_mean, Dv_fake_mean))\n",
    "\n",
    "        if epoch % n_epochs_saveV == 0:\n",
    "            save_video(fake_videos[0].data.cpu().numpy().transpose(1, 2, 3, 0), epoch)\n",
    "\n",
    "        if epoch % n_epochs_check == 0:\n",
    "            checkpoint(dis_i, optim_Di, epoch)\n",
    "            checkpoint(dis_v, optim_Dv, epoch)\n",
    "            checkpoint(gen_i, optim_Gi, epoch)\n",
    "            checkpoint(gru,   optim_GRU, epoch)\n",
    "        \n",
    "        time.sleep(10)\n",
    "          \n",
    "'''\n",
    "except RuntimeError:\n",
    "    print(\"Encountered a Runtime error. Not Solved by pytorch community, maybe is a problem with Scikit-video library. Restarting the loop.\")\n",
    "    epoch = epoch - 1\n",
    "    save_video(fake_videos[0].data.cpu().numpy().transpose(1, 2, 3, 0), epoch, True)\n",
    "    break\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Previous State\n",
    "---\n",
    "If wanted, the following cell can be used to load the previous state of a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' use pre-trained models '''\n",
    "\n",
    "def load():\n",
    "    dis_i.load_state_dict(torch.load(trained_path + '/Discriminator_I.model'))\n",
    "    dis_v.load_state_dict(torch.load(trained_path + '/Discriminator_V.model'))\n",
    "    gen_i.load_state_dict(torch.load(trained_path + '/Generator_I.model'))\n",
    "    gru.load_state_dict(torch.load(trained_path + '/GRU.model'))\n",
    "    optim_Di.load_state_dict(torch.load(trained_path + '/Discriminator_I.state'))\n",
    "    optim_Dv.load_state_dict(torch.load(trained_path + '/Discriminator_V.state'))\n",
    "    optim_Gi.load_state_dict(torch.load(trained_path + '/Generator_I.state'))\n",
    "    optim_GRU.load_state_dict(torch.load(trained_path + '/GRU.state'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, start training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training: CUDA is On\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/120000] (0d 0h 18m 58s) Loss_Di: 0.4657 Loss_Dv: 0.7419 Loss_Gi: 3.3966 Loss_Gv: 3.3440 Di_real_mean 0.8833 Di_fake_mean 0.0966 Dv_real_mean 0.3479 Dv_fake_mean 0.0148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/120000] (0d 0h 38m 6s) Loss_Di: 0.6351 Loss_Dv: 0.7131 Loss_Gi: 5.9900 Loss_Gv: 3.5543 Di_real_mean 0.9636 Di_fake_mean 0.1842 Dv_real_mean 0.5940 Dv_fake_mean 0.0335\n",
      "[3/120000] (0d 0h 57m 14s) Loss_Di: 0.4348 Loss_Dv: 0.7623 Loss_Gi: 2.7211 Loss_Gv: 2.8499 Di_real_mean 0.7792 Di_fake_mean 0.0256 Dv_real_mean 0.4821 Dv_fake_mean 0.0370\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/120000] (0d 1h 16m 24s) Loss_Di: 0.3965 Loss_Dv: 0.6176 Loss_Gi: 4.1970 Loss_Gv: 4.3891 Di_real_mean 0.8209 Di_fake_mean 0.0141 Dv_real_mean 0.4023 Dv_fake_mean 0.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/120000] (0d 1h 35m 35s) Loss_Di: 0.4957 Loss_Dv: 0.6038 Loss_Gi: 2.6068 Loss_Gv: 3.3309 Di_real_mean 0.8024 Di_fake_mean 0.0716 Dv_real_mean 0.5843 Dv_fake_mean 0.0442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/120000] (0d 1h 54m 44s) Loss_Di: 0.4697 Loss_Dv: 0.6306 Loss_Gi: 3.2583 Loss_Gv: 4.4402 Di_real_mean 0.7296 Di_fake_mean 0.0165 Dv_real_mean 0.5629 Dv_fake_mean 0.0338\n",
      "[7/120000] (0d 2h 13m 52s) Loss_Di: 0.4324 Loss_Dv: 0.8029 Loss_Gi: 4.3110 Loss_Gv: 2.2930 Di_real_mean 0.8198 Di_fake_mean 0.0214 Dv_real_mean 0.3127 Dv_fake_mean 0.0318\n",
      "[8/120000] (0d 2h 33m 0s) Loss_Di: 0.4219 Loss_Dv: 0.5531 Loss_Gi: 4.4171 Loss_Gv: 4.2890 Di_real_mean 0.9243 Di_fake_mean 0.0540 Dv_real_mean 0.5784 Dv_fake_mean 0.0304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/120000] (0d 2h 52m 8s) Loss_Di: 0.3941 Loss_Dv: 0.6505 Loss_Gi: 3.3263 Loss_Gv: 3.4847 Di_real_mean 0.8135 Di_fake_mean 0.0137 Dv_real_mean 0.5240 Dv_fake_mean 0.0556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/120000] (0d 3h 11m 20s) Loss_Di: 0.3802 Loss_Dv: 0.6176 Loss_Gi: 4.7201 Loss_Gv: 4.4672 Di_real_mean 0.8930 Di_fake_mean 0.0162 Dv_real_mean 0.4516 Dv_fake_mean 0.0055\n",
      "[11/120000] (0d 3h 30m 29s) Loss_Di: 0.4141 Loss_Dv: 0.6609 Loss_Gi: 3.6480 Loss_Gv: 3.4545 Di_real_mean 0.9517 Di_fake_mean 0.0406 Dv_real_mean 0.5301 Dv_fake_mean 0.0615\n",
      "[12/120000] (0d 3h 49m 41s) Loss_Di: 0.4384 Loss_Dv: 0.7059 Loss_Gi: 3.0311 Loss_Gv: 4.2427 Di_real_mean 0.8522 Di_fake_mean 0.0559 Dv_real_mean 0.5991 Dv_fake_mean 0.0381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/120000] (0d 4h 8m 53s) Loss_Di: 0.3906 Loss_Dv: 0.6997 Loss_Gi: 3.8728 Loss_Gv: 4.7274 Di_real_mean 0.8705 Di_fake_mean 0.0190 Dv_real_mean 0.5206 Dv_fake_mean 0.0217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/120000] (0d 4h 28m 0s) Loss_Di: 0.4107 Loss_Dv: 0.6237 Loss_Gi: 4.0828 Loss_Gv: 3.9822 Di_real_mean 0.9164 Di_fake_mean 0.0435 Dv_real_mean 0.4239 Dv_fake_mean 0.0126\n",
      "[15/120000] (0d 4h 47m 14s) Loss_Di: 0.4830 Loss_Dv: 0.6416 Loss_Gi: 5.3850 Loss_Gv: 4.0456 Di_real_mean 0.9601 Di_fake_mean 0.0688 Dv_real_mean 0.3733 Dv_fake_mean 0.0095\n",
      "[16/120000] (0d 5h 6m 23s) Loss_Di: 0.6050 Loss_Dv: 0.5475 Loss_Gi: 5.2723 Loss_Gv: 4.0026 Di_real_mean 0.6197 Di_fake_mean 0.0038 Dv_real_mean 0.4926 Dv_fake_mean 0.0374\n",
      "[17/120000] (0d 5h 25m 33s) Loss_Di: 0.3971 Loss_Dv: 0.5714 Loss_Gi: 4.0131 Loss_Gv: 3.4398 Di_real_mean 0.8652 Di_fake_mean 0.0318 Dv_real_mean 0.4874 Dv_fake_mean 0.0280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/120000] (0d 5h 44m 42s) Loss_Di: 0.4466 Loss_Dv: 0.7991 Loss_Gi: 2.8275 Loss_Gv: 4.0218 Di_real_mean 0.8779 Di_fake_mean 0.0670 Dv_real_mean 0.2774 Dv_fake_mean 0.0059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/120000] (0d 6h 3m 51s) Loss_Di: 0.4622 Loss_Dv: 0.6839 Loss_Gi: 3.9910 Loss_Gv: 3.7162 Di_real_mean 0.9341 Di_fake_mean 0.0905 Dv_real_mean 0.3203 Dv_fake_mean 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/120000] (0d 6h 23m 0s) Loss_Di: 0.3889 Loss_Dv: 0.5994 Loss_Gi: 3.6240 Loss_Gv: 4.3421 Di_real_mean 0.9236 Di_fake_mean 0.0398 Dv_real_mean 0.3089 Dv_fake_mean 0.0029\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/120000] (0d 6h 42m 9s) Loss_Di: 0.3853 Loss_Dv: 0.6000 Loss_Gi: 4.5342 Loss_Gv: 4.4777 Di_real_mean 0.8670 Di_fake_mean 0.0224 Dv_real_mean 0.5043 Dv_fake_mean 0.0226\n",
      "[22/120000] (0d 7h 1m 19s) Loss_Di: 0.3800 Loss_Dv: 0.7104 Loss_Gi: 4.0985 Loss_Gv: 4.1505 Di_real_mean 0.8827 Di_fake_mean 0.0251 Dv_real_mean 0.6417 Dv_fake_mean 0.0548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/120000] (0d 7h 20m 31s) Loss_Di: 0.3859 Loss_Dv: 0.5930 Loss_Gi: 4.1359 Loss_Gv: 4.6143 Di_real_mean 0.8623 Di_fake_mean 0.0276 Dv_real_mean 0.5101 Dv_fake_mean 0.0085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n",
      "/home/carlo/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/120000] (0d 7h 39m 39s) Loss_Di: 0.4926 Loss_Dv: 0.5725 Loss_Gi: 3.2029 Loss_Gv: 4.0992 Di_real_mean 0.7226 Di_fake_mean 0.0119 Dv_real_mean 0.4436 Dv_fake_mean 0.0285\n"
     ]
    }
   ],
   "source": [
    "load()\n",
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

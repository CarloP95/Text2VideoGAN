{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of MoCoGAN\n",
    "---\n",
    "In this Notebook is covered the topic of training the MoCoGAN and the fine tuning of this network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining global variables and imports\n",
    "---\n",
    "In the below cell all of the imports that are needed to the training and some global variables like `device` to use the GPU if available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import skvideo.io\n",
    "import numpy as np\n",
    "\n",
    "from glob import glob\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim, cuda as cu, device, manual_seed\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Lambda, Compose\n",
    "\n",
    "## Try to avoid problems with dataloader.\n",
    "\"\"\"\n",
    "import torch.multiprocessing as mp\n",
    "\n",
    "try:\n",
    "    mp.set_start_method('forkserver')\n",
    "    #mp.set_start_method('spawn')\n",
    "except RuntimeError as errs:\n",
    "    print(errs)\n",
    "\"\"\"\n",
    "##########################################\n",
    "\n",
    "'''Import variables from train.py'''\n",
    "img_size = 96\n",
    "nc = 3\n",
    "ndf = 64 # from dcgan\n",
    "ngf = 64\n",
    "d_E = 10\n",
    "hidden_size = 100 # guess\n",
    "d_C = 50\n",
    "d_M = d_E\n",
    "nz  = d_C + d_M\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "T = 16 # Hyperparameter for taking #Frames into discriminator.\n",
    "\n",
    "ngpu       = 1\n",
    "batch_size = 16\n",
    "n_iter     = 120000\n",
    "pre_train  = False\n",
    "\n",
    "## Addition for training on UCF-101\n",
    "n_epochs_saveV      = 1\n",
    "n_epochs_display    = 1\n",
    "n_epochs_check      = 1\n",
    "max_frame           = 25\n",
    "cuda                = True #For compatibility with old version of MocoGan\n",
    "#### End of additions\n",
    "\n",
    "\n",
    "seed = 0\n",
    "manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "device = device(\"cuda\" if cu.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of Models\n",
    "From the `models` module, let's import all of the models and let's load the previous state for fine tuning.\n",
    "\n",
    "Then models are moved into the device chosen in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"./mocogan/\")\n",
    "from models import Discriminator_I, Discriminator_V, Generator_I ,GRU, UCF_101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "./mocogan/models.py:238: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(params)\n",
      "./mocogan/models.py:248: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
      "  init.constant(params, 0)\n"
     ]
    }
   ],
   "source": [
    "'''Create the objects for Discriminator_(I|V), GRU and Generator_I'''\n",
    "gen_i = Generator_I(nc, ngf, nz, ngpu = 1, batch_size= batch_size)\n",
    "gru = GRU(d_E, hidden_size, gpu = cu.is_available())\n",
    "dis_i = Discriminator_I(nc, ndf, ngpu = 1)\n",
    "dis_v = Discriminator_V(nc, ndf, T = T, ngpu = 1)\n",
    "gru.initWeight()\n",
    "\n",
    "'''Move objects into the device chosen'''\n",
    "''' adjust to cuda '''\n",
    "if cuda == True:\n",
    "    dis_i.cuda()\n",
    "    dis_v.cuda()\n",
    "    gen_i.cuda()\n",
    "    gru.cuda()\n",
    "    criterion.cuda()\n",
    "\n",
    "'''Optimizer Settings and Optimizer'''\n",
    "lr = 0.0002\n",
    "betas=(0.5, 0.999)\n",
    "optim_Di  = optim.Adam(dis_i.parameters(), lr=lr, betas=betas)\n",
    "optim_Dv  = optim.Adam(dis_v.parameters(), lr=lr, betas=betas)\n",
    "optim_Gi  = optim.Adam(gen_i.parameters(), lr=lr, betas=betas)\n",
    "optim_GRU = optim.Adam(gru.parameters(),   lr=lr, betas=betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader\n",
    "---\n",
    "In the cells below, the dataloader will be defined and also all of the transformation that will be applied to the videos before taking them into a batch.\n",
    "To apply transformation to videos, since torchvision does not have a set of methods for this task, a repository called `torch_videovision` has been forked and modified to support transformation on numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/carlo/anaconda3/lib/python3.6/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n"
     ]
    }
   ],
   "source": [
    "from torch_videovision.videotransforms.video_transforms import ColorJitter, RandomTemporalCrop, RandomHorizontalFlip, RandomCrop\n",
    "from torch_videovision.videotransforms.volume_transforms import ToTensor, ClipToTensor, TransposeChannels\n",
    "from torch_videovision.videotransforms.tensor_transforms import Normalize, SpatialRandomCrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_path = !pwd\n",
    "current_path = str(current_path[0])\n",
    "resized_path = os.path.join(current_path, \"mocogan\", 'resized_data')\n",
    "files = glob(os.path.join(resized_path, \"*\", \"*\"))\n",
    "\n",
    "dict_dir = os.path.join(current_path, \"mocogan\", \"ucfTrainTestlist\", \"classInd.txt\")\n",
    "raw_path = os.path.join(current_path, \"mocogan\", \"raw_data\")\n",
    "raw_files = glob(os.path.join(raw_path, \"*\", \"*\"))\n",
    "\n",
    "'''\n",
    "transformation = Compose([Lambda(lambda video: video.transpose(3, 0, 1, 2)/255.0),\n",
    "                            Lambda(lambda video: video[ : , : max_frame, :, : ]),\n",
    "                            Lambda(lambda video: torch.FloatTensor(video))])\n",
    "'''\n",
    "\n",
    "transformation = Compose([  TransposeChannels(),\n",
    "                            RandomTemporalCrop(max_frame),\n",
    "                            SpatialRandomCrop( (img_size, img_size) ),\n",
    "                            RandomHorizontalFlip(),\n",
    "                            ColorJitter(1, 1, 1, 0.5), #Max Values for Color Jitter\n",
    "                            ClipToTensor(numpy = True, div_255= True),\n",
    "                            Normalize(0.5, 0.5),\n",
    "                            ToTensor()])\n",
    "\n",
    "\n",
    "dataset = UCF_101(raw_path, dict_dir, supportedExtensions= [\"avi\"], transform= transformation)\n",
    "dataloader = DataLoader(dataset, batch_size= batch_size, num_workers= 8, shuffle= True, pin_memory= True, drop_last= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "---\n",
    "\n",
    "In the cells below, first some methods to generate the Noise needed for the GAN is defined, then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Utilities'''\n",
    "def trim(video):\n",
    "    start = np.random.randint(0, video.shape[1] - (T+1))\n",
    "    end = start + T\n",
    "    return video[:, start:end, :, :]\n",
    "\n",
    "# for input noises to generate fake video\n",
    "# note that noises are trimmed randomly from n_frames to T for efficiency\n",
    "def trim_noise(noise):\n",
    "    #print(\"-----TRIMMING NOISE-----\")\n",
    "    #print(f\"Noise Size: {noise.size()}\")\n",
    "    start = np.random.randint(0, noise.size(1) - (T+1))\n",
    "    end = start + T\n",
    "    #print(\"-----END OF TRIMMING NOISE-----\")\n",
    "    return noise[:, start:end, :, :, :]\n",
    "\n",
    "\n",
    "''' calc grad of models '''\n",
    "\n",
    "def bp_i(inputs, y, retain=False):\n",
    "    label = (torch.FloatTensor()).cuda()\n",
    "    label.resize_(inputs.size(0)).fill_(y)\n",
    "    labelv = Variable(label)\n",
    "    outputs = dis_i(inputs)\n",
    "    \n",
    "    prompt_string = \"Fake\" if y == 0 else \"True\"\n",
    "    print(f\"Values from Discriminator_I {outputs}, {prompt_string}  Data\")\n",
    "    \n",
    "    err = criterion(outputs, labelv)\n",
    "    err.backward(retain_graph=retain)\n",
    "    toReturnErr = err.data[0] if err.size() == torch.Tensor().size() else err.item()\n",
    "    return toReturnErr, outputs.data.mean()\n",
    "\n",
    "def bp_v(inputs, labels, y, retain=False):\n",
    "    #print(\"----BackPropagate_V-----\")\n",
    "    #print(inputs.size())\n",
    "    label = (torch.FloatTensor()).cuda()\n",
    "    try:\n",
    "        label.resize_(inputs.size(0)).fill_(y)\n",
    "\n",
    "    except RuntimeError as _:\n",
    "        # Dimension of y does not allow to use fill_\n",
    "        assert(inputs.size(0) == y.size(0))\n",
    "        label = (torch.FloatTensor(y)).cuda()\n",
    "\n",
    "    labelv = Variable(label)\n",
    "    outputs = dis_v(inputs, labels)\n",
    "    \n",
    "    prompt_string = \"Fake\" if y == 0 else \"True\"\n",
    "    print(f\"Values from Discriminator_V {outputs}, {prompt_string}  Data\")\n",
    "    \n",
    "    err = criterion(outputs, labelv)\n",
    "    err.backward(retain_graph=retain)\n",
    "    toReturnErr = err.data[0] if err.size() == torch.Tensor().size() else err.item()\n",
    "    #print(\"----End of BackPropagate_V-----\")\n",
    "    return toReturnErr, outputs.data.mean()\n",
    "\n",
    "\n",
    "''' gen input noise for fake video '''\n",
    "\n",
    "def gen_z(n_frames, batch_size = batch_size):\n",
    "    #print(\"----Generating Z-----\")\n",
    "    #print(f\"N_FRAMES: {n_frames}\")\n",
    "    #print(f\"BATCH_SIZE: {batch_size}\")\n",
    "    #print(f\"D_C: {d_C}\")\n",
    "    #print(f\"D_E: {d_E}\")\n",
    "    #print(f\"nz: {nz}\")\n",
    "    z_C = Variable(torch.randn(batch_size, d_C))\n",
    "    #  repeat z_C to (batch_size, n_frames, d_C)\n",
    "    z_C = z_C.unsqueeze(1).repeat(1, n_frames, 1)\n",
    "    eps = Variable(torch.randn(batch_size, d_E))\n",
    "    if cuda == True:\n",
    "        z_C, eps = z_C.cuda(), eps.cuda()\n",
    "\n",
    "    gru.initHidden(batch_size)\n",
    "    # notice that 1st dim of gru outputs is seq_len, 2nd is batch_size\n",
    "    z_M = gru(eps, n_frames).transpose(1, 0)\n",
    "    z = torch.cat((z_M, z_C), 2)  # z.size() => (batch_size, n_frames, nz)\n",
    "    #print(\"----End Generating Z-----\")\n",
    "    return z.view(batch_size, n_frames, nz, 1, 1)\n",
    "\n",
    "''' prepare for train '''\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    d = math.floor(s / ((60**2)*24))\n",
    "    h = math.floor(s / (60**2)) - d*24\n",
    "    m = math.floor(s / 60) - h*60 - d*24*60\n",
    "    s = s - m*60 - h*(60**2) - d*24*(60**2)\n",
    "    return '%dd %dh %dm %ds' % (d, h, m, s)\n",
    "\n",
    "trained_path = os.path.join(current_path, \"mocogan\", 'trained_models')\n",
    "def checkpoint(model, optimizer, epoch):\n",
    "    filename = os.path.join(trained_path, '%s_epoch-%d' % (model.__class__.__name__, epoch))\n",
    "    torch.save(model.state_dict(), filename + '.model')\n",
    "    torch.save(optimizer.state_dict(), filename + '.state')\n",
    "\n",
    "def save_video(fake_video, epoch):\n",
    "    outputdata = fake_video * 255\n",
    "    outputdata = outputdata.astype(np.uint8)\n",
    "    dir_path = os.path.join(current_path, 'mocogan', 'generated_videos')\n",
    "    file_path = os.path.join(dir_path, 'fakeVideo_epoch-%d.mp4' % (epoch))\n",
    "    skvideo.io.vwrite(file_path, outputdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' train models '''\n",
    "def train():\n",
    "    \n",
    "    start_time = time.time()\n",
    "\n",
    "    print(f\"Starting training: CUDA is { 'On' if cuda == True else 'Off'}\")\n",
    "\n",
    "    for epoch in range(1, n_iter+1):\n",
    "        ''' prepare real images '''\n",
    "        # real_videos.size() => (batch_size, nc, T, img_size, img_size)\n",
    "\n",
    "        # Get data iterator\n",
    "        updateEvery_Generator_I_GRU = 3\n",
    "        fake_label = 0\n",
    "        true_label = [val for val in range(1, 102)]\n",
    "        data_iter = iter(dataloader) #Iterator\n",
    "        data_len = len(dataloader) #Num Batches\n",
    "        data_i = 0\n",
    "\n",
    "        while data_i < data_len:\n",
    "\n",
    "            try:\n",
    "          \n",
    "                (real_videos, labels) = next(data_iter)\n",
    "                  \n",
    "                print(f\"\\r--------Batch {data_i}/{data_len}---------\", end = \"\")\n",
    "                #for (key, val) in dataset.class_to_idx.items():\n",
    "                #    if ( val in labels.tolist() ):\n",
    "                #        #print(key)\n",
    "                #        pass\n",
    "\n",
    "                if cuda == True:\n",
    "                    real_videos = real_videos.cuda()\n",
    "                    labels = labels.cuda()\n",
    "          \n",
    "                real_videos = Variable(real_videos)\n",
    "                real_img = real_videos[:, :, np.random.randint(0, T), :, :]\n",
    "\n",
    "                ''' prepare fake images '''\n",
    "                # note that n_frames is sampled from video length distribution\n",
    "                if (len(dataset.videoLengths) > 0):\n",
    "                    randomVideo = list(dataset.videoLengths)[np.random.randint(0, len(dataset.videoLengths))]\n",
    "                    n_frames = dataset.videoLengths[randomVideo]\n",
    "          \n",
    "                else: # Use this for first iterations, when dataset.videoLengths is not yet updated.\n",
    "                    n_frames = T + 2 + np.random.randint(0, real_videos.size()[2])\n",
    "          \n",
    "                Z = gen_z(n_frames, batch_size)  # Z.size() => (batch_size, n_frames, nz, 1, 1)\n",
    "                # trim => (batch_size, T, nz, 1, 1)\n",
    "                Z = trim_noise(Z)\n",
    "                # generate videos\n",
    "                Z = Z.contiguous().view(batch_size*T, nz, 1, 1)\n",
    "                \n",
    "                fake_videos = gen_i(Z, labels)\n",
    "                fake_videos = fake_videos.view(batch_size, T, nc, img_size, img_size)\n",
    "                # transpose => (batch_size, nc, T, img_size, img_size)\n",
    "                fake_videos = fake_videos.transpose(2, 1)\n",
    "                # img sampling\n",
    "                fake_img = fake_videos[:, :, np.random.randint(0, T), :, :]\n",
    "\n",
    "                ''' train discriminators '''\n",
    "                # video\n",
    "                dis_v.zero_grad()\n",
    "                randomStartFrameIdx = np.random.randint(0, real_videos.size()[2] - T - 1)\n",
    "                #print(\"-----INFOS-----\")\n",
    "                #print(f\"RandomStartFrame:{randomStartFrameIdx}\")\n",
    "                #print(f\"Video Size:{real_videos.size()}\")\n",
    "                #print(\"-----END OF INFOS-----\")\n",
    "                croppedRealVideos = real_videos[:,:,randomStartFrameIdx: randomStartFrameIdx + T, :, :]\n",
    "                err_Dv_real, Dv_real_mean = bp_v(croppedRealVideos, labels, 0.9)\n",
    "                #err_Dv_real, Dv_real_mean = bp_v(croppedRealVideos, labels.type(torch.FloatTensor) / len(dictClassesIdx))\n",
    "                err_Dv_fake, Dv_fake_mean = bp_v(fake_videos.detach(), labels, fake_label)\n",
    "                err_Dv = err_Dv_real + err_Dv_fake\n",
    "                optim_Dv.step()\n",
    "                # image\n",
    "                dis_i.zero_grad()\n",
    "                err_Di_real, Di_real_mean = bp_i(real_img, 0.9)\n",
    "                err_Di_fake, Di_fake_mean = bp_i(fake_img.detach(), fake_label)\n",
    "                err_Di = err_Di_real + err_Di_fake\n",
    "                optim_Di.step()\n",
    "\n",
    "\n",
    "                ''' train generators '''\n",
    "                gen_i.zero_grad()\n",
    "                gru.zero_grad()\n",
    "                # video. notice retain=True for back prop twice\n",
    "                err_Gv, _ = bp_v(fake_videos, labels, 0.9, retain=True)\n",
    "                # images\n",
    "                err_Gi, _ = bp_i(fake_img, 0.9)\n",
    "          \n",
    "                if epoch % updateEvery_Generator_I_GRU == 0:\n",
    "                    optim_Gi.step()\n",
    "                    optim_GRU.step()\n",
    "\n",
    "                '''Increment index for Batch'''\n",
    "                data_i = data_i + 1\n",
    "          \n",
    "                '''Cool down the Hardware'''\n",
    "                time.sleep(1/2)\n",
    "          \n",
    "            except StopIteration:\n",
    "                break\n",
    "            \n",
    "            except KeyboardInterrupt:\n",
    "                save_video(fake_videos[0].data.cpu().numpy().transpose(1, 2, 3, 0), epoch)\n",
    "                checkpoint(dis_i, optim_Di, epoch)\n",
    "                checkpoint(dis_v, optim_Dv, epoch)\n",
    "                checkpoint(gen_i, optim_Gi, epoch)\n",
    "                checkpoint(gru,   optim_GRU, epoch)\n",
    "\n",
    "        if epoch % n_epochs_display == 0:\n",
    "            print('[%d/%d] (%s) Loss_Di: %.4f Loss_Dv: %.4f Loss_Gi: %.4f Loss_Gv: %.4f Di_real_mean %.4f Di_fake_mean %.4f Dv_real_mean %.4f Dv_fake_mean %.4f'\n",
    "                  % (epoch, n_iter, timeSince(start_time), err_Di, err_Dv, err_Gi, err_Gv, Di_real_mean, Di_fake_mean, Dv_real_mean, Dv_fake_mean))\n",
    "\n",
    "        if epoch % n_epochs_saveV == 0:\n",
    "            save_video(fake_videos[0].data.cpu().numpy().transpose(1, 2, 3, 0), epoch)\n",
    "\n",
    "        if epoch % n_epochs_check == 0:\n",
    "            checkpoint(dis_i, optim_Di, epoch)\n",
    "            checkpoint(dis_v, optim_Dv, epoch)\n",
    "            checkpoint(gen_i, optim_Gi, epoch)\n",
    "            checkpoint(gru,   optim_GRU, epoch)\n",
    "          \n",
    "        '''Cool down the Hardware'''\n",
    "        time.sleep(5)\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Previous State\n",
    "---\n",
    "If wanted, the following cell can be used to load the previous state of a trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' use pre-trained models '''\n",
    "\n",
    "def load():\n",
    "    dis_i.load_state_dict(torch.load(trained_path + '/Discriminator_I.model'))\n",
    "    dis_v.load_state_dict(torch.load(trained_path + '/Discriminator_V.model'))\n",
    "    gen_i.load_state_dict(torch.load(trained_path + '/Generator_I.model'))\n",
    "    gru.load_state_dict(torch.load(trained_path + '/GRU.model'))\n",
    "    optim_Di.load_state_dict(torch.load(trained_path + '/Discriminator_I.state'))\n",
    "    optim_Dv.load_state_dict(torch.load(trained_path + '/Discriminator_V.state'))\n",
    "    optim_Gi.load_state_dict(torch.load(trained_path + '/Generator_I.state'))\n",
    "    optim_GRU.load_state_dict(torch.load(trained_path + '/GRU.state'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, start training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training: CUDA is On\n",
      "(3, 25, 96, 96) <class 'numpy.ndarray'> [[[[213 206 214 ... 144 150 151]\n",
      "   [255 255 255 ... 148 155 155]\n",
      "   [241 237 234 ... 152 158 158]\n",
      "   ...\n",
      "   [243 240 237 ...  43  41  41]\n",
      "   [243 240 237 ...  43  41  41]\n",
      "   [243 240 238 ...  43  41  41]]\n",
      "\n",
      "  [[183 177 184 ... 150 151 154]\n",
      "   [240 241 247 ... 155 155 158]\n",
      "   [242 241 241 ... 158 158 160]\n",
      "   ...\n",
      "   [241 239 236 ...  43  41  41]\n",
      "   [241 239 236 ...  43  41  41]\n",
      "   [241 239 237 ...  43  41  41]]\n",
      "\n",
      "  [[174 190 196 ... 144 147 152]\n",
      "   [234 252 254 ... 153 154 158]\n",
      "   [238 244 241 ... 157 158 160]\n",
      "   ...\n",
      "   [251 246 242 ...  43  41  41]\n",
      "   [250 245 241 ...  43  41  41]\n",
      "   [246 244 241 ...  43  41  41]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 62  63  66 ...  73  74  74]\n",
      "   [ 93  93  98 ...  79  78  75]\n",
      "   [214 214 222 ... 100  95  90]\n",
      "   ...\n",
      "   [ 63  62  67 ...  44  44  44]\n",
      "   [ 49  54  58 ...  44  44  44]\n",
      "   [ 66  75  73 ...  44  44  44]]\n",
      "\n",
      "  [[ 62  63  66 ...  73  74  74]\n",
      "   [ 93  93  98 ...  79  78  75]\n",
      "   [214 214 222 ... 100  95  90]\n",
      "   ...\n",
      "   [ 41  48  57 ...  44  44  44]\n",
      "   [ 54  49  53 ...  44  44  44]\n",
      "   [ 47  48  47 ...  44  44  44]]\n",
      "\n",
      "  [[ 78  78  70 ...  78  77  76]\n",
      "   [114 118 118 ...  77  74  74]\n",
      "   [229 232 230 ...  92  90  90]\n",
      "   ...\n",
      "   [ 62  53  52 ...  44  45  45]\n",
      "   [ 61  67  61 ...  44  45  45]\n",
      "   [ 30  36  37 ...  44  45  45]]]\n",
      "\n",
      "\n",
      " [[[206 199 207 ... 143 150 151]\n",
      "   [249 251 253 ... 149 156 156]\n",
      "   [231 227 224 ... 153 159 159]\n",
      "   ...\n",
      "   [232 229 226 ...  53  51  51]\n",
      "   [232 229 226 ...  53  51  51]\n",
      "   [232 229 227 ...  53  51  51]]\n",
      "\n",
      "  [[175 169 176 ... 150 151 154]\n",
      "   [230 231 237 ... 156 156 159]\n",
      "   [232 231 231 ... 159 159 161]\n",
      "   ...\n",
      "   [230 228 225 ...  53  51  51]\n",
      "   [230 228 225 ...  53  51  51]\n",
      "   [230 228 226 ...  53  51  51]]\n",
      "\n",
      "  [[166 182 189 ... 144 147 152]\n",
      "   [223 241 248 ... 154 155 159]\n",
      "   [227 233 235 ... 158 159 161]\n",
      "   ...\n",
      "   [232 227 224 ...  53  51  51]\n",
      "   [231 226 223 ...  53  51  51]\n",
      "   [229 227 223 ...  53  51  51]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 69  70  73 ...  84  85  85]\n",
      "   [ 95  95  99 ...  89  89  86]\n",
      "   [216 216 223 ... 110 106 101]\n",
      "   ...\n",
      "   [ 69  68  70 ...  56  56  56]\n",
      "   [ 55  60  61 ...  56  56  56]\n",
      "   [ 69  78  74 ...  56  56  56]]\n",
      "\n",
      "  [[ 69  70  73 ...  84  85  85]\n",
      "   [ 95  95  99 ...  89  89  86]\n",
      "   [216 216 223 ... 110 106 101]\n",
      "   ...\n",
      "   [ 47  54  63 ...  56  56  56]\n",
      "   [ 60  55  59 ...  56  56  56]\n",
      "   [ 50  51  50 ...  56  56  56]]\n",
      "\n",
      "  [[ 82  82  74 ...  93  93  92]\n",
      "   [113 117 117 ...  90  85  85]\n",
      "   [228 231 229 ... 105 101 101]\n",
      "   ...\n",
      "   [ 61  52  52 ...  54  55  55]\n",
      "   [ 60  66  61 ...  54  55  55]\n",
      "   [ 27  33  35 ...  54  55  55]]]\n",
      "\n",
      "\n",
      " [[[209 202 210 ... 132 134 135]\n",
      "   [250 252 254 ... 128 133 133]\n",
      "   [232 228 225 ... 132 136 136]\n",
      "   ...\n",
      "   [215 212 209 ...  50  48  48]\n",
      "   [215 212 209 ...  50  48  48]\n",
      "   [215 212 210 ...  50  48  48]]\n",
      "\n",
      "  [[181 175 182 ... 136 135 138]\n",
      "   [234 235 241 ... 135 133 136]\n",
      "   [236 235 235 ... 138 136 138]\n",
      "   ...\n",
      "   [213 211 208 ...  50  48  48]\n",
      "   [213 211 208 ...  50  48  48]\n",
      "   [213 211 209 ...  50  48  48]]\n",
      "\n",
      "  [[174 190 199 ... 130 131 136]\n",
      "   [230 248 255 ... 135 134 138]\n",
      "   [234 240 242 ... 139 138 140]\n",
      "   ...\n",
      "   [209 204 203 ...  50  48  48]\n",
      "   [208 203 202 ...  50  48  48]\n",
      "   [205 203 202 ...  50  48  48]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 64  65  66 ...  85  84  84]\n",
      "   [ 92  92  91 ...  81  78  75]\n",
      "   [213 213 215 ... 102  95  90]\n",
      "   ...\n",
      "   [ 56  55  58 ...  52  52  52]\n",
      "   [ 42  47  49 ...  52  52  52]\n",
      "   [ 49  58  55 ...  52  52  52]]\n",
      "\n",
      "  [[ 64  65  66 ...  85  84  84]\n",
      "   [ 92  92  91 ...  81  78  75]\n",
      "   [213 213 215 ... 102  95  90]\n",
      "   ...\n",
      "   [ 34  41  50 ...  52  52  52]\n",
      "   [ 47  42  46 ...  52  52  52]\n",
      "   [ 30  31  30 ...  52  52  52]]\n",
      "\n",
      "  [[ 84  84  76 ...  96  93  92]\n",
      "   [116 120 120 ...  89  84  84]\n",
      "   [231 234 232 ... 104 100 100]\n",
      "   ...\n",
      "   [ 50  41  38 ...  51  52  52]\n",
      "   [ 49  55  47 ...  51  52  52]\n",
      "   [ 12  18  17 ...  51  52  52]]]](3, 25, 96, 96) <class 'numpy.ndarray'> [[[[211 218 230 ... 136 138 142]\n",
      "   [244 246 250 ... 135 135 137]\n",
      "   [253 252 250 ... 141 138 140]\n",
      "   ...\n",
      "   [231 230 230 ...  86 104 116]\n",
      "   [235 234 231 ...  87  99 106]\n",
      "   [213 214 217 ...  89  94  96]]\n",
      "\n",
      "  [[ 95  89  93 ...  24  25  29]\n",
      "   [100 109 130 ...  24  25  29]\n",
      "   [160 181 202 ...  24  25  29]\n",
      "   ...\n",
      "   [220 220 220 ... 167 148 135]\n",
      "   [220 220 220 ... 188 177 171]\n",
      "   [220 220 220 ... 187 182 184]]\n",
      "\n",
      "  [[ 90  89  96 ...  22  24  24]\n",
      "   [105 121 142 ...  22  24  24]\n",
      "   [173 194 211 ...  22  24  24]\n",
      "   ...\n",
      "   [221 220 220 ... 195 187 169]\n",
      "   [221 220 220 ... 195 192 183]\n",
      "   [221 220 220 ... 194 191 186]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 51  42  37 ... 108 108 108]\n",
      "   [ 49  41  36 ... 108 108 109]\n",
      "   [ 52  47  39 ... 108 108 108]\n",
      "   ...\n",
      "   [  9  11  11 ... 187 187 188]\n",
      "   [  9  11  11 ... 186 186 188]\n",
      "   [ 11  11  11 ... 186 186 187]]\n",
      "\n",
      "  [[ 56  49  45 ... 113 112 112]\n",
      "   [ 66  56  51 ... 110 110 110]\n",
      "   [ 74  64  57 ... 109 109 110]\n",
      "   ...\n",
      "   [ 12  13  14 ... 193 193 193]\n",
      "   [ 12  13  14 ... 192 192 192]\n",
      "   [ 12  12  13 ... 191 191 191]]\n",
      "\n",
      "  [[ 56  49  45 ... 112 112 110]\n",
      "   [ 66  56  51 ... 109 109 110]\n",
      "   [ 74  64  57 ... 108 108 108]\n",
      "   ...\n",
      "   [ 12  13  14 ... 193 193 193]\n",
      "   [ 12  13  14 ... 192 192 192]\n",
      "   [ 12  12  13 ... 191 191 191]]]\n",
      "\n",
      "\n",
      " [[[211 218 230 ... 137 139 143]\n",
      "   [244 246 250 ... 138 138 140]\n",
      "   [253 252 250 ... 144 141 143]\n",
      "   ...\n",
      "   [250 249 249 ...  98 116 128]\n",
      "   [254 253 250 ...  99 111 118]\n",
      "   [232 233 236 ... 101 106 108]]\n",
      "\n",
      "  [[ 95  89  93 ...  29  30  34]\n",
      "   [100 109 130 ...  29  30  34]\n",
      "   [160 181 202 ...  29  30  34]\n",
      "   ...\n",
      "   [239 239 239 ... 183 160 147]\n",
      "   [239 239 239 ... 204 189 183]\n",
      "   [239 239 239 ... 203 197 199]]\n",
      "\n",
      "  [[ 90  89  96 ...  27  29  29]\n",
      "   [105 121 142 ...  27  29  29]\n",
      "   [173 194 211 ...  27  29  29]\n",
      "   ...\n",
      "   [240 239 239 ... 211 202 184]\n",
      "   [240 239 239 ... 211 207 198]\n",
      "   [240 239 239 ... 210 207 202]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 42  33  26 ... 110 110 110]\n",
      "   [ 43  35  27 ... 110 110 111]\n",
      "   [ 46  41  30 ... 110 110 110]\n",
      "   ...\n",
      "   [ 12  14  14 ... 205 207 208]\n",
      "   [ 12  14  14 ... 204 206 208]\n",
      "   [ 14  14  14 ... 201 204 205]]\n",
      "\n",
      "  [[ 40  33  25 ... 115 114 114]\n",
      "   [ 53  43  33 ... 112 112 112]\n",
      "   [ 61  51  39 ... 111 111 112]\n",
      "   ...\n",
      "   [ 15  16  17 ... 213 213 213]\n",
      "   [ 15  16  17 ... 212 212 212]\n",
      "   [ 15  15  16 ... 211 211 211]]\n",
      "\n",
      "  [[ 40  33  25 ... 114 114 112]\n",
      "   [ 53  43  33 ... 111 111 112]\n",
      "   [ 61  51  39 ... 110 110 110]\n",
      "   ...\n",
      "   [ 15  16  17 ... 213 213 213]\n",
      "   [ 15  16  17 ... 212 212 212]\n",
      "   [ 15  15  16 ... 211 211 211]]]\n",
      "\n",
      "\n",
      " [[[211 218 230 ... 125 127 131]\n",
      "   [244 246 250 ... 130 130 132]\n",
      "   [253 252 250 ... 136 133 135]\n",
      "   ...\n",
      "   [255 255 255 ...  91 109 121]\n",
      "   [255 255 255 ...  92 104 111]\n",
      "   [240 241 244 ...  97 102 104]]\n",
      "\n",
      "  [[ 95  89  93 ...  39  40  44]\n",
      "   [100 109 130 ...  39  40  44]\n",
      "   [160 181 202 ...  39  40  44]\n",
      "   ...\n",
      "   [249 249 249 ... 194 166 153]\n",
      "   [249 249 249 ... 215 195 189]\n",
      "   [249 249 249 ... 214 202 204]]\n",
      "\n",
      "  [[ 90  89  96 ...  37  39  39]\n",
      "   [105 121 142 ...  37  39  39]\n",
      "   [173 194 211 ...  37  39  39]\n",
      "   ...\n",
      "   [250 249 249 ... 222 209 191]\n",
      "   [250 249 249 ... 222 214 205]\n",
      "   [250 249 249 ... 221 216 211]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 34  25  19 ... 105 105 105]\n",
      "   [ 36  28  21 ... 105 105 106]\n",
      "   [ 39  34  24 ... 105 105 105]\n",
      "   ...\n",
      "   [ 23  25  23 ... 222 221 222]\n",
      "   [ 23  25  23 ... 221 220 222]\n",
      "   [ 25  25  23 ... 217 221 222]]\n",
      "\n",
      "  [[ 36  29  18 ... 112 111 111]\n",
      "   [ 48  38  28 ... 107 107 107]\n",
      "   [ 56  46  34 ... 106 106 107]\n",
      "   ...\n",
      "   [ 24  25  24 ... 227 227 227]\n",
      "   [ 24  25  24 ... 226 226 226]\n",
      "   [ 24  24  23 ... 225 225 225]]\n",
      "\n",
      "  [[ 36  29  18 ... 109 109 107]\n",
      "   [ 48  38  28 ... 106 106 107]\n",
      "   [ 56  46  34 ... 105 105 105]\n",
      "   ...\n",
      "   [ 24  25  24 ... 227 227 227]\n",
      "   [ 24  25  24 ... 226 226 226]\n",
      "   [ 24  24  23 ... 225 225 225]]]]\n",
      "\n",
      "(3, 25, 96, 96) <class 'numpy.ndarray'> [[[[150 150 150 ... 248 255 249]\n",
      "   [152 152 152 ... 220 255 218]\n",
      "   [154 154 154 ... 179 225 230]\n",
      "   ...\n",
      "   [183 183 183 ... 180 180 176]\n",
      "   [183 183 183 ... 180 180 176]\n",
      "   [183 183 183 ... 180 180 176]]\n",
      "\n",
      "  [[151 150 150 ... 178 220 227]\n",
      "   [151 151 151 ... 186 231 199]\n",
      "   [151 157 157 ... 213 254 198]\n",
      "   ...\n",
      "   [183 183 183 ... 180 180 176]\n",
      "   [183 183 183 ... 180 180 176]\n",
      "   [183 183 183 ... 180 180 176]]\n",
      "\n",
      "  [[152 151 151 ... 185 213 160]\n",
      "   [152 152 152 ... 167 206 131]\n",
      "   [150 156 156 ... 156 204 129]\n",
      "   ...\n",
      "   [183 183 183 ... 180 180 189]\n",
      "   [183 183 183 ... 180 180 188]\n",
      "   [183 183 183 ... 180 180 189]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[168 169 169 ... 173 176 175]\n",
      "   [168 169 169 ... 165 169 186]\n",
      "   [169 168 168 ... 143 148 184]\n",
      "   ...\n",
      "   [182 182 182 ... 181 181 181]\n",
      "   [182 182 182 ... 181 181 181]\n",
      "   [182 182 182 ... 181 181 181]]\n",
      "\n",
      "  [[168 169 169 ... 173 175 183]\n",
      "   [168 169 169 ... 169 173 182]\n",
      "   [169 168 168 ... 154 159 169]\n",
      "   ...\n",
      "   [182 182 182 ... 181 181 181]\n",
      "   [182 182 182 ... 181 181 181]\n",
      "   [182 182 182 ... 181 181 181]]\n",
      "\n",
      "  [[171 171 171 ... 172 174 185]\n",
      "   [171 171 171 ... 168 172 189]\n",
      "   [173 173 173 ... 155 159 184]\n",
      "   ...\n",
      "   [182 182 182 ... 180 180 182]\n",
      "   [182 182 182 ... 178 178 182]\n",
      "   [182 182 182 ... 178 178 182]]]\n",
      "\n",
      "\n",
      " [[[150 150 150 ... 243 255 244]\n",
      "   [152 152 152 ... 215 250 213]\n",
      "   [154 154 154 ... 174 220 225]\n",
      "   ...\n",
      "   [186 186 186 ... 186 186 183]\n",
      "   [186 186 186 ... 186 186 183]\n",
      "   [186 186 186 ... 186 186 183]]\n",
      "\n",
      "  [[151 150 150 ... 173 215 222]\n",
      "   [151 151 151 ... 181 226 194]\n",
      "   [151 157 157 ... 208 249 193]\n",
      "   ...\n",
      "   [186 186 186 ... 186 186 183]\n",
      "   [186 186 186 ... 186 186 183]\n",
      "   [186 186 186 ... 186 186 183]]\n",
      "\n",
      "  [[152 151 151 ... 180 208 155]\n",
      "   [152 152 152 ... 162 201 126]\n",
      "   [150 156 156 ... 151 199 124]\n",
      "   ...\n",
      "   [186 186 186 ... 186 186 196]\n",
      "   [186 186 186 ... 186 186 195]\n",
      "   [186 186 186 ... 186 186 196]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[166 167 167 ... 171 174 173]\n",
      "   [166 167 167 ... 163 167 184]\n",
      "   [167 166 166 ... 141 146 182]\n",
      "   ...\n",
      "   [188 188 188 ... 187 187 187]\n",
      "   [188 188 188 ... 187 187 187]\n",
      "   [188 188 188 ... 187 187 187]]\n",
      "\n",
      "  [[166 167 167 ... 171 173 181]\n",
      "   [166 167 167 ... 167 171 180]\n",
      "   [167 166 166 ... 152 157 167]\n",
      "   ...\n",
      "   [188 188 188 ... 187 187 187]\n",
      "   [188 188 188 ... 187 187 187]\n",
      "   [188 188 188 ... 187 187 187]]\n",
      "\n",
      "  [[169 169 169 ... 170 172 180]\n",
      "   [169 169 169 ... 166 170 184]\n",
      "   [171 171 171 ... 153 157 179]\n",
      "   ...\n",
      "   [187 187 187 ... 188 188 186]\n",
      "   [187 187 187 ... 186 186 186]\n",
      "   [188 188 188 ... 186 186 186]]]\n",
      "\n",
      "\n",
      " [[[150 150 150 ... 240 255 246]\n",
      "   [152 152 152 ... 212 247 215]\n",
      "   [154 154 154 ... 171 217 227]\n",
      "   ...\n",
      "   [135 135 135 ... 147 147 135]\n",
      "   [135 135 135 ... 147 147 135]\n",
      "   [135 135 135 ... 147 147 135]]\n",
      "\n",
      "  [[151 150 150 ... 170 212 219]\n",
      "   [151 151 151 ... 180 225 193]\n",
      "   [151 157 157 ... 207 248 192]\n",
      "   ...\n",
      "   [135 135 135 ... 147 147 135]\n",
      "   [135 135 135 ... 147 147 135]\n",
      "   [135 135 135 ... 147 147 135]]\n",
      "\n",
      "  [[152 151 151 ... 177 205 152]\n",
      "   [152 152 152 ... 159 198 123]\n",
      "   [150 156 156 ... 148 196 121]\n",
      "   ...\n",
      "   [135 135 135 ... 147 147 148]\n",
      "   [135 135 135 ... 147 147 147]\n",
      "   [135 135 135 ... 147 147 148]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[164 165 165 ... 169 172 169]\n",
      "   [164 165 165 ... 161 165 180]\n",
      "   [165 164 164 ... 139 144 178]\n",
      "   ...\n",
      "   [138 138 138 ... 148 148 148]\n",
      "   [138 138 138 ... 148 148 148]\n",
      "   [138 138 138 ... 146 146 146]]\n",
      "\n",
      "  [[164 165 165 ... 169 171 179]\n",
      "   [164 165 165 ... 165 169 176]\n",
      "   [165 164 164 ... 150 155 163]\n",
      "   ...\n",
      "   [138 138 138 ... 148 148 148]\n",
      "   [138 138 138 ... 148 148 148]\n",
      "   [138 138 138 ... 146 146 146]]\n",
      "\n",
      "  [[167 167 167 ... 168 170 179]\n",
      "   [167 167 167 ... 164 168 183]\n",
      "   [169 169 169 ... 151 155 178]\n",
      "   ...\n",
      "   [140 140 140 ... 149 149 146]\n",
      "   [140 140 140 ... 147 147 146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   [138 138 138 ... 147 147 146]]]]\n",
      "(3, 25, 96, 96) <class 'numpy.ndarray'> [[[[ 75  75  75 ... 249 249 249]\n",
      "   [ 75  75  76 ... 250 250 250]\n",
      "   [ 75  75  76 ... 252 252 252]\n",
      "   ...\n",
      "   [ 78  95 102 ...  47  45  45]\n",
      "   [ 81  93  93 ...  47  45  45]\n",
      "   [ 85  92  87 ...  47  45  45]]\n",
      "\n",
      "  [[ 75  75  75 ... 249 249 249]\n",
      "   [ 75  75  76 ... 250 250 250]\n",
      "   [ 75  75  76 ... 252 252 252]\n",
      "   ...\n",
      "   [ 78  95 102 ...  48  46  46]\n",
      "   [ 81  93  93 ...  48  46  46]\n",
      "   [ 85  92  87 ...  48  46  46]]\n",
      "\n",
      "  [[ 78  78  77 ... 248 248 248]\n",
      "   [ 78  78  77 ... 250 250 250]\n",
      "   [ 78  78  80 ... 252 252 252]\n",
      "   ...\n",
      "   [ 76  92  93 ...  49  47  47]\n",
      "   [ 80  95  85 ...  49  47  47]\n",
      "   [ 93  83  48 ...  49  47  47]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 85  85  87 ... 230 249 254]\n",
      "   [ 84  85  85 ... 238 252 253]\n",
      "   [ 84  84  85 ... 247 254 254]\n",
      "   ...\n",
      "   [103 130 122 ...  54  48  43]\n",
      "   [108 129 112 ...  55  47  40]\n",
      "   [118 125 104 ...  54  45  38]]\n",
      "\n",
      "  [[ 85  85  84 ... 234 251 253]\n",
      "   [ 84  85  84 ... 244 254 255]\n",
      "   [ 84  84  87 ... 251 255 255]\n",
      "   ...\n",
      "   [104 128 116 ...  54  48  42]\n",
      "   [110 124 106 ...  54  46  40]\n",
      "   [119 112  95 ...  51  43  38]]\n",
      "\n",
      "  [[ 84  84  83 ... 226 247 254]\n",
      "   [ 84  84  87 ... 240 254 255]\n",
      "   [ 84  84  88 ... 252 255 255]\n",
      "   ...\n",
      "   [100 126 120 ...  48  41  37]\n",
      "   [108 125 109 ...  47  40  36]\n",
      "   [117 123 102 ...  47  40  34]]]\n",
      "\n",
      "\n",
      " [[[ 63  63  63 ... 240 240 240]\n",
      "   [ 63  63  64 ... 241 241 241]\n",
      "   [ 63  63  64 ... 243 244 244]\n",
      "   ...\n",
      "   [ 51  68  75 ...  33  33  33]\n",
      "   [ 56  68  68 ...  33  33  33]\n",
      "   [ 60  67  62 ...  33  33  33]]\n",
      "\n",
      "  [[ 63  63  63 ... 240 240 240]\n",
      "   [ 63  63  64 ... 241 241 241]\n",
      "   [ 63  63  64 ... 243 243 243]\n",
      "   ...\n",
      "   [ 51  68  75 ...  33  34  34]\n",
      "   [ 56  68  68 ...  33  34  34]\n",
      "   [ 60  67  62 ...  33  34  34]]\n",
      "\n",
      "  [[ 66  66  65 ... 242 243 243]\n",
      "   [ 66  66  65 ... 244 245 245]\n",
      "   [ 66  66  68 ... 246 247 247]\n",
      "   ...\n",
      "   [ 51  67  68 ...  37  37  37]\n",
      "   [ 55  70  60 ...  37  37  37]\n",
      "   [ 68  58  23 ...  37  37  37]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 73  73  75 ... 226 245 250]\n",
      "   [ 72  73  73 ... 234 248 249]\n",
      "   [ 72  72  73 ... 242 250 250]\n",
      "   ...\n",
      "   [ 67  94  86 ...  38  37  32]\n",
      "   [ 74  95  78 ...  39  36  29]\n",
      "   [ 84  91  70 ...  38  34  27]]\n",
      "\n",
      "  [[ 73  73  72 ... 230 247 249]\n",
      "   [ 72  73  72 ... 240 250 251]\n",
      "   [ 72  72  75 ... 246 250 250]\n",
      "   ...\n",
      "   [ 70  94  82 ...  38  35  29]\n",
      "   [ 78  92  74 ...  38  33  27]\n",
      "   [ 87  80  63 ...  35  30  25]]\n",
      "\n",
      "  [[ 72  72  71 ... 223 243 250]\n",
      "   [ 72  72  75 ... 237 250 255]\n",
      "   [ 72  72  76 ... 248 252 254]\n",
      "   ...\n",
      "   [ 66  92  86 ...  35  30  26]\n",
      "   [ 76  93  77 ...  34  29  25]\n",
      "   [ 85  91  70 ...  34  29  23]]]\n",
      "\n",
      "\n",
      " [[[ 51  51  51 ... 234 232 232]\n",
      "   [ 51  51  52 ... 235 233 233]\n",
      "   [ 51  51  52 ... 235 233 233]\n",
      "   ...\n",
      "   [ 33  50  57 ...  19  21  21]\n",
      "   [ 37  49  51 ...  19  21  21]\n",
      "   [ 41  48  45 ...  19  21  21]]\n",
      "\n",
      "  [[ 51  51  51 ... 234 232 232]\n",
      "   [ 51  51  52 ... 235 233 233]\n",
      "   [ 51  51  52 ... 237 235 235]\n",
      "   ...\n",
      "   [ 33  50  57 ...  22  24  24]\n",
      "   [ 37  49  51 ...  22  24  24]\n",
      "   [ 41  48  45 ...  22  24  24]]\n",
      "\n",
      "  [[ 54  54  53 ... 233 231 231]\n",
      "   [ 54  54  53 ... 235 233 233]\n",
      "   [ 54  54  56 ... 237 235 235]\n",
      "   ...\n",
      "   [ 32  48  49 ...  25  27  27]\n",
      "   [ 36  51  43 ...  25  27  27]\n",
      "   [ 49  39   6 ...  25  27  27]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 61  61  63 ... 218 237 242]\n",
      "   [ 60  61  61 ... 226 240 241]\n",
      "   [ 60  60  61 ... 239 244 244]\n",
      "   ...\n",
      "   [ 47  74  66 ...  34  32  27]\n",
      "   [ 56  77  60 ...  35  31  24]\n",
      "   [ 66  73  52 ...  34  29  22]]\n",
      "\n",
      "  [[ 61  61  60 ... 222 239 241]\n",
      "   [ 60  61  60 ... 232 242 243]\n",
      "   [ 60  60  63 ... 243 245 245]\n",
      "   ...\n",
      "   [ 52  76  64 ...  34  32  26]\n",
      "   [ 62  76  58 ...  34  30  24]\n",
      "   [ 71  64  47 ...  31  27  22]]\n",
      "\n",
      "  [[ 60  60  59 ... 210 233 240]\n",
      "   [ 60  60  63 ... 224 240 245]\n",
      "   [ 60  60  64 ... 240 244 246]\n",
      "   ...\n",
      "   [ 48  74  68 ...  30  25  21]\n",
      "   [ 60  77  61 ...  29  24  20]\n",
      "   [ 69  75  54 ...  29  24  18]]]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/carlo/anaconda3/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 99, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/carlo/anaconda3/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 99, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"./mocogan/models.py\", line 441, in __getitem__\n    readVideo = self.transform(readVideo)\n  File \"/home/carlo/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n    img = t(img)\n  File \"/home/carlo/Documenti/Text2VideoGAN/torch_videovision/videotransforms/tensor_transforms.py\", line 30, in __call__\n    return F.normalize(tensor, self.mean, self.std)\n  File \"/home/carlo/Documenti/Text2VideoGAN/torch_videovision/videotransforms/utils/functional.py\", line 9, in normalize\n    tensor.sub_(mean).div_(std)\nAttributeError: 'numpy.ndarray' object has no attribute 'sub_'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-ea71085321f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#load()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-1eff1b29647e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mreal_videos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\r--------Batch {data_i}/{data_len}---------\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__next__\u001b[0m  \u001b[0;31m# Python 2 compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    606\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KeyError:\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Traceback (most recent call last):\n  File \"/home/carlo/anaconda3/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 99, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/carlo/anaconda3/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 99, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"./mocogan/models.py\", line 441, in __getitem__\n    readVideo = self.transform(readVideo)\n  File \"/home/carlo/anaconda3/lib/python3.6/site-packages/torchvision/transforms/transforms.py\", line 61, in __call__\n    img = t(img)\n  File \"/home/carlo/Documenti/Text2VideoGAN/torch_videovision/videotransforms/tensor_transforms.py\", line 30, in __call__\n    return F.normalize(tensor, self.mean, self.std)\n  File \"/home/carlo/Documenti/Text2VideoGAN/torch_videovision/videotransforms/utils/functional.py\", line 9, in normalize\n    tensor.sub_(mean).div_(std)\nAttributeError: 'numpy.ndarray' object has no attribute 'sub_'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 25, 96, 96) <class 'numpy.ndarray'> [[[[ 42  42  42 ...  40  40  40]\n",
      "   [ 42  42  42 ...  40  40  40]\n",
      "   [ 42  42  42 ...  40  40  40]\n",
      "   ...\n",
      "   [  2   1   1 ...   0   0   0]\n",
      "   [ 11  10   9 ...   2   3   3]\n",
      "   [  4   3   3 ...   0   0   0]]\n",
      "\n",
      "  [[ 45  45  45 ...  41  38  37]\n",
      "   [ 46  46  46 ...  41  39  38]\n",
      "   [ 46  46  46 ...  41  40  39]\n",
      "   ...\n",
      "   [  2   1   1 ...   1   2   2]\n",
      "   [ 11  10   8 ...   2   1   0]\n",
      "   [  4   3   2 ...   0   0   4]]\n",
      "\n",
      "  [[ 41  41  41 ...  95  80  58]\n",
      "   [ 42  42  42 ... 100  86  71]\n",
      "   [ 45  45  45 ...  97  90  83]\n",
      "   ...\n",
      "   [  3   2   2 ...   1   2   0]\n",
      "   [  8   6   5 ...   1   0   0]\n",
      "   [  4   3   2 ...   0   1   6]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 41  41  41 ...  41  41  40]\n",
      "   [ 41  41  41 ...  43  41  41]\n",
      "   [ 42  42  42 ...  43  41  41]\n",
      "   ...\n",
      "   [  1   1   1 ...   0   0   0]\n",
      "   [  0   0   0 ...   0   0   0]\n",
      "   [  0   0   0 ...   1   1   1]]\n",
      "\n",
      "  [[ 41  41  41 ... 112  76  38]\n",
      "   [ 42  42  42 ... 112  79  39]\n",
      "   [ 42  42  42 ... 114  81  41]\n",
      "   ...\n",
      "   [  1   1   1 ...   0   0   0]\n",
      "   [  0   0   0 ...   0   0   0]\n",
      "   [  0   0   0 ...   1   1   1]]\n",
      "\n",
      "  [[ 42  42  42 ... 115  81  40]\n",
      "   [ 42  42  42 ... 121  88  44]\n",
      "   [ 42  42  42 ... 116  87  44]\n",
      "   ...\n",
      "   [  3   3   3 ...   1   1   1]\n",
      "   [  0   0   0 ...   0   0   0]\n",
      "   [  2   2   1 ...   2   2   2]]]\n",
      "\n",
      "\n",
      " [[[ 44  44  44 ...  40  40  40]\n",
      "   [ 44  44  44 ...  40  40  40]\n",
      "   [ 44  44  44 ...  40  40  40]\n",
      "   ...\n",
      "   [  2   1   1 ...   0   0   0]\n",
      "   [ 11  10   9 ...   2   3   3]\n",
      "   [  4   3   3 ...   0   0   0]]\n",
      "\n",
      "  [[ 45  45  45 ...  41  38  37]\n",
      "   [ 46  46  46 ...  41  39  38]\n",
      "   [ 46  46  46 ...  41  40  39]\n",
      "   ...\n",
      "   [  2   1   1 ...   1   2   2]\n",
      "   [ 11  10   8 ...   2   1   0]\n",
      "   [  4   3   2 ...   0   0   4]]\n",
      "\n",
      "  [[ 43  43  43 ...  95  80  58]\n",
      "   [ 44  44  44 ... 100  86  71]\n",
      "   [ 45  45  45 ...  97  90  83]\n",
      "   ...\n",
      "   [  3   2   2 ...   1   2   0]\n",
      "   [  8   6   5 ...   1   0   0]\n",
      "   [  4   3   2 ...   0   1   6]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 44  44  44 ...  41  41  40]\n",
      "   [ 44  44  44 ...  43  41  41]\n",
      "   [ 45  45  45 ...  43  41  41]\n",
      "   ...\n",
      "   [  1   1   1 ...   0   0   0]\n",
      "   [  0   0   0 ...   0   0   0]\n",
      "   [  0   0   0 ...   1   1   1]]\n",
      "\n",
      "  [[ 44  44  44 ... 112  76  38]\n",
      "   [ 45  45  45 ... 112  79  39]\n",
      "   [ 45  45  45 ... 114  81  41]\n",
      "   ...\n",
      "   [  1   1   1 ...   0   0   0]\n",
      "   [  0   0   0 ...   0   0   0]\n",
      "   [  0   0   0 ...   1   1   1]]\n",
      "\n",
      "  [[ 45  45  45 ... 115  81  40]\n",
      "   [ 45  45  45 ... 121  88  44]\n",
      "   [ 45  45  45 ... 116  87  44]\n",
      "   ...\n",
      "   [  3   3   3 ...   1   1   1]\n",
      "   [  0   0   0 ...   0   0   0]\n",
      "   [  2   2   1 ...   2   2   2]]]\n",
      "\n",
      "\n",
      " [[[ 39  39  39 ...  37  37  37]\n",
      "   [ 39  39  39 ...  37  37  37]\n",
      "   [ 39  39  39 ...  37  37  37]\n",
      "   ...\n",
      "   [  0   0   0 ...   0   0   0]\n",
      "   [  8   7   6 ...   2   3   3]\n",
      "   [  1   0   0 ...   0   0   0]]\n",
      "\n",
      "  [[ 42  42  42 ...  38  35  34]\n",
      "   [ 43  43  43 ...  38  36  35]\n",
      "   [ 43  43  43 ...  38  37  36]\n",
      "   ...\n",
      "   [  0   0   0 ...   1   2   2]\n",
      "   [  8   7   5 ...   2   1   0]\n",
      "   [  1   0   0 ...   0   0   4]]\n",
      "\n",
      "  [[ 38  38  38 ...  92  77  55]\n",
      "   [ 39  39  39 ...  97  83  68]\n",
      "   [ 42  42  42 ...  94  87  80]\n",
      "   ...\n",
      "   [  0   0   0 ...   1   2   0]\n",
      "   [  5   3   2 ...   1   0   0]\n",
      "   [  1   0   0 ...   0   1   6]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 36  36  36 ...  38  38  37]\n",
      "   [ 36  36  36 ...  40  38  38]\n",
      "   [ 37  37  37 ...  40  38  38]\n",
      "   ...\n",
      "   [  0   0   0 ...   0   0   0]\n",
      "   [  0   0   0 ...   0   0   0]\n",
      "   [  0   0   0 ...   1   1   1]]\n",
      "\n",
      "  [[ 36  36  36 ... 109  73  35]\n",
      "   [ 37  37  37 ... 109  76  36]\n",
      "   [ 37  37  37 ... 111  78  38]\n",
      "   ...\n",
      "   [  0   0   0 ...   0   0   0]\n",
      "   [  0   0   0 ...   0   0   0]\n",
      "   [  0   0   0 ...   1   1   1]]\n",
      "\n",
      "  [[ 37  37  37 ... 112  78  37]\n",
      "   [ 37  37  37 ... 118  85  41]\n",
      "   [ 37  37  37 ... 113  84  41]\n",
      "   ...\n",
      "   [  3   3   3 ...   1   1   1]\n",
      "   [  0   0   0 ...   0   0   0]\n",
      "   [  2   2   1 ...   2   2   2]]]]\n"
     ]
    }
   ],
   "source": [
    "#load()\n",
    "train() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text To Video\n",
    "\n",
    "In this notebook the project will be exposed with its normal operating mode.\n",
    "\n",
    "First let's import the Generator Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mocogan.models import VideoGenerator\n",
    "\n",
    "n_channels      = 3\n",
    "dim_z_content   = 50\n",
    "dim_z_category  = 2 #101\n",
    "dim_z_motion    = 10\n",
    "video_length    = 16\n",
    "cuda            = True\n",
    "\n",
    "trained_classes = {\"Surfing\" : 1, \"PlayingPiano\": 2}\n",
    "\n",
    "gen = VideoGenerator(n_channels, dim_z_content, dim_z_category, dim_z_motion, video_length, cuda, class_to_idx = trained_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths\n",
    "Let's define paths to retrieve model state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "current_path = !pwd\n",
    "current_path = current_path[0]\n",
    "\n",
    "trained_path = os.path.join(current_path, 'mocogan', 'trained_models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load saved State\n",
    "Now load saved state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mocogan.trainer import loadState\n",
    "\n",
    "loadState(80, gen, path = trained_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LSTM Model \n",
    "\n",
    "Let's load LSTM model to get the category predicted from natural language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import os\n",
    "from glob import glob\n",
    "from TextToClass.models import LSTM\n",
    "from TextToClass.dataloading import TextLoader\n",
    "\n",
    "rnnType     = nn.LSTM\n",
    "rnnSize     = 512\n",
    "embedSize   = 256\n",
    "itemLength  = 10\n",
    "loadEpoch   = 75\n",
    "\n",
    "\n",
    "dataset_path = os.path.join(current_path, 'caffe', 'examples', 's2vt', 'results', '[!val]*')\n",
    "dataset_path = glob(dataset_path)[0]\n",
    "\n",
    "dataset = TextLoader(dataset_path, item_length = itemLength)\n",
    "\n",
    "network = LSTM(rnnType, rnnSize, embedSize, dataset.vocabulary )\n",
    "\n",
    "network.loadState(loadEpoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Video from your input\n",
    "\n",
    "Now put a input and let's generate a video. \n",
    "\n",
    "First cell will take your input and tell you the predicted class.\n",
    "\n",
    "Second cell will generate and save the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Put your input here: > A group of men are dancing and running on the ice\n",
      "Predicted class is bandmarching\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "humanDescription     = input('Put your input here: > ')\n",
    "\n",
    "try:\n",
    "    toForwardDescription = dataset.prepareTxtForTensor(humanDescription)\n",
    "    results              = network(torch.tensor(toForwardDescription).unsqueeze_(0))\n",
    "    _, actionIDx         = results.max(1)\n",
    "    actionClassName      = dataset.getClassNameFromIndex(actionIDx.item() + 1)\n",
    "    print(f'Predicted class is {actionClassName}')    \n",
    "    \n",
    "except KeyError as err:\n",
    "    print('Sorry, that word is not in the vocabulary. Please try again.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoCoGAN was trained on less categories, the video class that will be created is Surfing\n"
     ]
    }
   ],
   "source": [
    "from mocogan.trainer import save_video\n",
    "\n",
    "mean   = (100.99800554447337/255, 96.7195209000943/255, 89.63882431650443/255)\n",
    "std    = (72.07041943699456/255, 70.41506399740703/255, 71.55581999303428/255)\n",
    "\n",
    "gen      = gen.cuda()\n",
    "\n",
    "n_videos = 1\n",
    "n_frames = 25 * 3 # 3s\n",
    "\n",
    "save_path =  current_path\n",
    "\n",
    "actionIDx       = torch.tensor(dim_z_category - 2) if actionIDx.item() >= dim_z_category else actionIDx\n",
    "actionClassName = gen.getCorrectClassName(actionIDx.item() + 1)\n",
    "\n",
    "print(f'MoCoGAN was trained on less categories, the video class that will be created is {actionClassName}')\n",
    "\n",
    "fakeVideo, _ = gen.sample_videos(n_videos, n_frames, [actionIDx.item() + 1])\n",
    "fakeVideo    = fakeVideo[0].detach().cpu().numpy().transpose(1, 2, 3, 0)\n",
    "save_video(fakeVideo, actionClassName, 0, std, mean, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video controls  >\n",
       " <source src=\"data:None;base64,./fake_Surfing_epoch-0.mp4\" type=\"None\">\n",
       " Your browser does not support the video tag.\n",
       " </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "import numpy as np\n",
    "\n",
    "Video(f'./fake_{actionClassName}_epoch-0.mp4', embed= True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

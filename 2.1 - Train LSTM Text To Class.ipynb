{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train LSTM\n",
    "In this notebook the process of training on the extracted descriptions of UCF_101."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameters for training\n",
    "Let's define the parameters used for training of the model and some paths used.\n",
    "\n",
    "If you want to train on the dirty dataset (with duplicates), use the commented line, else use the following cell as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "\n",
    "current_path = !pwd\n",
    "current_path = current_path[0]\n",
    "\n",
    "#dataset_path = os.path.join(current_path, 'caffe', 'examples', 's2vt', 'results', 'dataset_Action_Description.txt')\n",
    "dataset_path = os.path.join(current_path, 'TextToClass', 'processed_dataset.txt')\n",
    "\n",
    "cuda          = True\n",
    "epochs        = 100\n",
    "numClasses    = 101\n",
    "path          = dataset_path\n",
    "batch_size    = 64\n",
    "weight_decay  = 5e-4\n",
    "lr            = 1e-4\n",
    "rnn_type      = nn.LSTM\n",
    "rnn_size      = 512\n",
    "embed_size    = 256\n",
    "save_interval = 20\n",
    "sequence_len  = 10\n",
    "load_epoch    = 0\n",
    "\n",
    "parameters =  {\n",
    "        'cuda'          : cuda,\n",
    "        'epochs'        : epochs,\n",
    "        'numClasses'    : numClasses,\n",
    "        'path'          : path,\n",
    "        'batch_size'    : batch_size,\n",
    "        'weight_decay'  : weight_decay,\n",
    "        'lr'            : lr,\n",
    "        'rnn_size'      : rnn_size,\n",
    "        'embed_size'    : embed_size,\n",
    "        'loadEpoch'     : load_epoch,\n",
    "        'save_interval' : save_interval,\n",
    "        'sequence_len'  : sequence_len\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataloader and TextLoader\n",
    "Let's create the dataset and the dataloader objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TextToClass.dataloading import DataLoaderFactory, TextLoader\n",
    "\n",
    "dataset         = TextLoader(parameters['path'], item_length= parameters['sequence_len'])\n",
    "factory         = DataLoaderFactory(dataset, parameters['batch_size'])\n",
    "\n",
    "\n",
    "train_dataLoader, validation_dataLoader, test_dataLoader = factory.dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model\n",
    "In the next cells the model will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TextToClass.models import LSTM\n",
    "\n",
    "network = LSTM(rnn_type, parameters['rnn_size'], parameters['embed_size'], dataset.vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the device on which the training will happen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "dev = torch.device('cuda') if torch.cuda.is_available() and parameters['cuda'] else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the trainer and start training the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TextToClass.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(network, train_dataLoader, parameters['epochs'], device = dev, testLoader= test_dataLoader,\n",
    "                 validLoader= validation_dataLoader, lr = parameters['lr'], weight_decay= parameters['weight_decay'],\n",
    "                 save_interval= parameters['save_interval'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------Epoch 1----------\n",
      "Batch [44/44] Train\t Loss: 4.5599, Accuracy: 0.0156\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.5930, Accuracy: 0.0312\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.4959, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 1/100, Train: Loss=4.5860, Accuracy =0.0210.                Validation: Loss=4.5439, Accuracy=0.0170.                Test: Loss=4.5344, Accuracy=0.0240.\n",
      "\n",
      "----------Epoch 2----------\n",
      "Batch [44/44] Train\t Loss: 4.5070, Accuracy: 0.0625\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.5574, Accuracy: 0.0156\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.4525, Accuracy: 0.0469\n",
      "\n",
      "Epoch: 2/100, Train: Loss=4.5223, Accuracy =0.0369.                Validation: Loss=4.5136, Accuracy=0.0284.                Test: Loss=4.4969, Accuracy=0.0385.\n",
      "\n",
      "----------Epoch 3----------\n",
      "Batch [44/44] Train\t Loss: 4.4774, Accuracy: 0.0312\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.5701, Accuracy: 0.0156\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.4211, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 3/100, Train: Loss=4.4797, Accuracy =0.0472.                Validation: Loss=4.4883, Accuracy=0.0384.                Test: Loss=4.4575, Accuracy=0.0505.\n",
      "\n",
      "Probable overfit is occurring. Next epoch weights will be loaded and learning rate will be updated.\n",
      "----------Epoch 4----------\n",
      "Batch [44/44] Train\t Loss: 4.3764, Accuracy: 0.0781\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.2925, Accuracy: 0.0469\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.3127, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 4/100, Train: Loss=4.4077, Accuracy =0.0579.                Validation: Loss=4.4243, Accuracy=0.0341.                Test: Loss=4.3730, Accuracy=0.0541.\n",
      "\n",
      "Overfit Detected. Loading back 2 epochs ago and reducing learning rate.\n",
      "----------Epoch 5----------\n",
      "Batch [44/44] Train\t Loss: 4.3242, Accuracy: 0.0469\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.4278, Accuracy: 0.0156\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.2981, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 5/100, Train: Loss=4.3205, Accuracy =0.0678.                Validation: Loss=4.4090, Accuracy=0.0341.                Test: Loss=4.3573, Accuracy=0.0589.\n",
      "\n",
      "Probable overfit is occurring. Next epoch weights will be loaded and learning rate will be updated.\n",
      "----------Epoch 6----------\n",
      "Batch [44/44] Train\t Loss: 4.1615, Accuracy: 0.0625\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.2586, Accuracy: 0.0312\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.2803, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 6/100, Train: Loss=4.3023, Accuracy =0.0700.                Validation: Loss=4.3940, Accuracy=0.0369.                Test: Loss=4.3421, Accuracy=0.0625.\n",
      "\n",
      "Overfit Detected. Loading back 2 epochs ago and reducing learning rate.\n",
      "----------Epoch 7----------\n",
      "Batch [44/44] Train\t Loss: 4.3208, Accuracy: 0.0781\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.5231, Accuracy: 0.0000\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.2782, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 7/100, Train: Loss=4.2891, Accuracy =0.0732.                Validation: Loss=4.3927, Accuracy=0.0369.                Test: Loss=4.3406, Accuracy=0.0625.\n",
      "\n",
      "Probable overfit is occurring. Next epoch weights will be loaded and learning rate will be updated.\n",
      "----------Epoch 8----------\n",
      "Batch [44/44] Train\t Loss: 4.2372, Accuracy: 0.1250\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.4395, Accuracy: 0.0469\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.2766, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 8/100, Train: Loss=4.2873, Accuracy =0.0728.                Validation: Loss=4.3892, Accuracy=0.0369.                Test: Loss=4.3391, Accuracy=0.0637.\n",
      "\n",
      "Overfit Detected. Loading back 2 epochs ago and reducing learning rate.\n",
      "----------Epoch 9----------\n",
      "Batch [44/44] Train\t Loss: 4.3031, Accuracy: 0.0469\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.4498, Accuracy: 0.0000\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.2764, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 9/100, Train: Loss=4.2855, Accuracy =0.0739.                Validation: Loss=4.3930, Accuracy=0.0369.                Test: Loss=4.3390, Accuracy=0.0637.\n",
      "\n",
      "Probable overfit is occurring. Next epoch weights will be loaded and learning rate will be updated.\n",
      "----------Epoch 10----------\n",
      "Batch [44/44] Train\t Loss: 4.3872, Accuracy: 0.0469\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.2969, Accuracy: 0.0469\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.2763, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 10/100, Train: Loss=4.2852, Accuracy =0.0739.                Validation: Loss=4.3902, Accuracy=0.0369.                Test: Loss=4.3389, Accuracy=0.0637.\n",
      "\n",
      "Overfit Detected. Loading back 2 epochs ago and reducing learning rate.\n",
      "----------Epoch 11----------\n",
      "Batch [44/44] Train\t Loss: 4.3240, Accuracy: 0.0781\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.3516, Accuracy: 0.0312\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.2763, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 11/100, Train: Loss=4.2855, Accuracy =0.0735.                Validation: Loss=4.3932, Accuracy=0.0355.                Test: Loss=4.3389, Accuracy=0.0637.\n",
      "\n",
      "Probable overfit is occurring. Next epoch weights will be loaded and learning rate will be updated.\n",
      "----------Epoch 12----------\n",
      "Batch [44/44] Train\t Loss: 4.1717, Accuracy: 0.1094\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.3858, Accuracy: 0.0469\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.2762, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 12/100, Train: Loss=4.2854, Accuracy =0.0739.                Validation: Loss=4.3905, Accuracy=0.0369.                Test: Loss=4.3388, Accuracy=0.0637.\n",
      "\n",
      "Overfit Detected. Loading back 2 epochs ago and reducing learning rate.\n",
      "----------Epoch 13----------\n",
      "Batch [44/44] Train\t Loss: 4.2894, Accuracy: 0.0469\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.3521, Accuracy: 0.0469\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.2762, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 13/100, Train: Loss=4.2853, Accuracy =0.0739.                Validation: Loss=4.3913, Accuracy=0.0369.                Test: Loss=4.3388, Accuracy=0.0637.\n",
      "\n",
      "Probable overfit is occurring. Next epoch weights will be loaded and learning rate will be updated.\n",
      "----------Epoch 14----------\n",
      "Batch [44/44] Train\t Loss: 4.2266, Accuracy: 0.0938\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.2838, Accuracy: 0.0781\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.2762, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 14/100, Train: Loss=4.2856, Accuracy =0.0735.                Validation: Loss=4.3912, Accuracy=0.0369.                Test: Loss=4.3388, Accuracy=0.0637.\n",
      "\n",
      "Overfit Detected. Loading back 2 epochs ago and reducing learning rate.\n",
      "----------Epoch 15----------\n",
      "Batch [44/44] Train\t Loss: 4.1404, Accuracy: 0.1406\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.5116, Accuracy: 0.0625\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.2762, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 15/100, Train: Loss=4.2845, Accuracy =0.0739.                Validation: Loss=4.3910, Accuracy=0.0369.                Test: Loss=4.3388, Accuracy=0.0637.\n",
      "\n",
      "Probable overfit is occurring. Next epoch weights will be loaded and learning rate will be updated.\n",
      "----------Epoch 16----------\n",
      "Batch [44/44] Train\t Loss: 4.1768, Accuracy: 0.1094\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.3364, Accuracy: 0.0469\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.2762, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 16/100, Train: Loss=4.2855, Accuracy =0.0735.                Validation: Loss=4.3908, Accuracy=0.0369.                Test: Loss=4.3388, Accuracy=0.0637.\n",
      "\n",
      "Overfit Detected. Loading back 2 epochs ago and reducing learning rate.\n",
      "----------Epoch 17----------\n",
      "Batch [44/44] Train\t Loss: 4.1213, Accuracy: 0.1406\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.3384, Accuracy: 0.0469\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.2762, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 17/100, Train: Loss=4.2848, Accuracy =0.0739.                Validation: Loss=4.3901, Accuracy=0.0369.                Test: Loss=4.3388, Accuracy=0.0637.\n",
      "\n",
      "Probable overfit is occurring. Next epoch weights will be loaded and learning rate will be updated.\n",
      "----------Epoch 18----------\n",
      "Batch [44/44] Train\t Loss: 4.2699, Accuracy: 0.0781\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.3909, Accuracy: 0.0781\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.2762, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 18/100, Train: Loss=4.2850, Accuracy =0.0739.                Validation: Loss=4.3928, Accuracy=0.0369.                Test: Loss=4.3388, Accuracy=0.0637.\n",
      "\n",
      "Overfit Detected. Loading back 2 epochs ago and reducing learning rate.\n",
      "----------Epoch 19----------\n",
      "Batch [44/44] Train\t Loss: 4.1264, Accuracy: 0.1406\n",
      "\n",
      "Batch [11/11] Valid\t Loss: 4.3686, Accuracy: 0.0312\n",
      "\n",
      "Batch [13/13] Test\t Loss: 4.2762, Accuracy: 0.0312\n",
      "\n",
      "Epoch: 19/100, Train: Loss=4.2857, Accuracy =0.0735.                Validation: Loss=4.3895, Accuracy=0.0369.                Test: Loss=4.3388, Accuracy=0.0637.\n",
      "\n",
      "Probable overfit is occurring. Next epoch weights will be loaded and learning rate will be updated.\n",
      "----------Epoch 20----------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-2c26d16cbddf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documenti/Text2VideoGAN/TextToClass/trainer.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"valid\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"test\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtestLoader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m                 \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cycle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documenti/Text2VideoGAN/TextToClass/trainer.py\u001b[0m in \u001b[0;36m_cycle\u001b[0;34m(self, mode, loader)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0maccuracies\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_DataLoaderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loader)\u001b[0m\n\u001b[1;32m    467\u001b[0m                 \u001b[0;31m#     before it starts, and __del__ tries to join but will get:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m                 \u001b[0;31m#     AssertionError: can only join a started process.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m                 \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_queues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_queue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/process.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m                \u001b[0;34m'daemonic processes are not allowed to have children'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0m_cleanup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sentinel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_popen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentinel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;31m# Avoid a refcycle if the target function holds an indirect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    221\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProcess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDefaultContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseContext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/context.py\u001b[0m in \u001b[0;36m_Popen\u001b[0;34m(process_obj)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mpopen_fork\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[0;32mclass\u001b[0m \u001b[0mSpawnProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseProcess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush_std_streams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_launch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mduplicate_for_child\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/popen_fork.py\u001b[0m in \u001b[0;36m_launch\u001b[0;34m(self, process_obj)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mparent_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
